# -*- coding: utf-8 -*-
"""LSTM_Soft_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H4katUDp2Js42sAQfChj67OO3BAUz4CE
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import models
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
import sklearn
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers
from tensorflow.keras import activations

callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.02, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)

data = pd.read_pickle("Clean_Sig_Big_NONAN_Num.pkl", compression='infer', storage_options=None)
X = data[['BX','BY']]
PWM = data[['PWM5','PWM9','PWM10','PWM11']]
PWMOG = PWM
X = np.array(X)
X = StandardScaler().fit_transform(X)
PWM = StandardScaler().fit_transform(PWM)
XX = X[:-303]
PWM = np.array(PWM)
PWMM = PWM[:-303]
X_train, X_test, PWM_train, PWM_test = train_test_split(XX, PWMM, test_size=0.2,shuffle=False)
X_Train = np.array(X_train)
X_Test = np.array(X_test)
PWM_Train = np.array(PWM_train)
PWM_Test = np.array(PWM_test)
X_train_v1 = np.vsplit(X_train,3120)
X_TRAIN = np.array(X_train_v1)
X_test_v1 = np.vsplit(X_test,780)
X_TEST = np.array(X_test_v1)
PWM_Train_v1 = np.vsplit(PWM_Train,3120)
PWM_TRAIN = np.array(PWM_Train_v1)
PWM_Test_v1 = np.vsplit(PWM_Test,780)
PWM_TEST = np.array(PWM_Test_v1)
X_train_v2 = tf.convert_to_tensor(X_TRAIN)
PWM_train_v2 = tf.convert_to_tensor(PWM_TRAIN)
X_test_v2 = tf.convert_to_tensor(X_TEST)
PWM_test_v2 = tf.convert_to_tensor(PWM_TEST)

LSTM_Soft3 = Sequential(name='LSTM_Soft_3s')

LSTM_Soft3.add(Input(shape=(30,2)))
#LSTM_Soft3.add(LSTM(units = 512, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft3.add(layers.Activation(activations.gelu))
#LSTM_Soft3.add(Dropout(0.1))
LSTM_Soft3.add(LSTM(units = 256, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft3.add(layers.Activation(activations.gelu))
#LSTM_Soft3.add(Dropout(0.1))
LSTM_Soft3.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft9.add(Dropout(0.1))
LSTM_Soft3.add(LSTM(units = 4, return_sequences = True))
#LSTM_Soft3.add(layers.Activation(activations.gelu))
#LSTM_Soft3.add(Dropout(0.1))
LSTM_Soft3.add(tf.keras.layers.Reshape((30,4)))

LSTM_Soft3.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_Soft3.summary()

history3 = LSTM_Soft3.fit(X_train_v2, PWM_train_v2, batch_size = 2, epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)#callbacks = [callbacks],

plt.plot(history3.history['accuracy'], label='accuracy')
plt.plot(history3.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.2, 0.8])
plt.legend(loc='lower right')

plt.plot(history3.history['loss'], label='loss')
plt.plot(history3.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.4, 1.05])
plt.legend(loc='lower right')

data = pd.read_pickle("Clean_Sig_Big_NONAN_Num.pkl", compression='infer', storage_options=None)
X = data[['BX','BY']]
PWM = data[['PWM5','PWM9','PWM10','PWM11']]
PWMOG = PWM
X = np.array(X)
X = StandardScaler().fit_transform(X)
PWM = StandardScaler().fit_transform(PWM)
XX = X[:-303]
PWM = np.array(PWM)
PWMM = PWM[:-303]
X_train, X_test, PWM_train, PWM_test = train_test_split(XX, PWMM, test_size=0.2,shuffle=False)
X_Train = np.array(X_train)
X_Test = np.array(X_test)
PWM_Train = np.array(PWM_train)
PWM_Test = np.array(PWM_test)
X_train_v1 = np.vsplit(X_train,3120*3)
X_TRAIN = np.array(X_train_v1)
X_test_v1 = np.vsplit(X_test,780*3)
X_TEST = np.array(X_test_v1)
PWM_Train_v1 = np.vsplit(PWM_Train,3120*3)
PWM_TRAIN = np.array(PWM_Train_v1)
PWM_Test_v1 = np.vsplit(PWM_Test,780*3)
PWM_TEST = np.array(PWM_Test_v1)
print(PWM_TEST.shape)
X_train_v2 = tf.convert_to_tensor(X_TRAIN)
PWM_train_v2 = tf.convert_to_tensor(PWM_TRAIN)
X_test_v2 = tf.convert_to_tensor(X_TEST)
PWM_test_v2 = tf.convert_to_tensor(PWM_TEST)

LSTM_Soft1 = Sequential(name='LSTM_Soft_1s')

LSTM_Soft1.add(Input(shape=(10,2)))
LSTM_Soft1.add(LSTM(units = 256, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft1.add(layers.Activation(activations.gelu))
#LSTM_Soft1.add(Dropout(0.1))
LSTM_Soft1.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft1.add(layers.Activation(activations.gelu))
#LSTM_Soft1.add(Dropout(0.1))
LSTM_Soft1.add(LSTM(units = 4, return_sequences = True))
#LSTM_Soft1.add(layers.Activation(activations.gelu))
#LSTM_Soft1.add(Dropout(0.1))
LSTM_Soft1.add(tf.keras.layers.Reshape((10,4)))

LSTM_Soft1.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_Soft1.summary()

history1 = LSTM_Soft1.fit(X_train_v2, PWM_train_v2, batch_size = 2, epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True) #callbacks = [callbacks],

plt.plot(history1.history['accuracy'], label='accuracy')
plt.plot(history1.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.2, 0.8])
plt.legend(loc='lower right')

plt.plot(history1.history['loss'], label='loss')
plt.plot(history1.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.4, 1.05])
plt.legend(loc='lower right')

data = pd.read_pickle("Clean_Sig_Big_NONAN_Num.pkl", compression='infer', storage_options=None)
X = data[['BX','BY']]
PWM = data[['PWM5','PWM9','PWM10','PWM11']]
PWMOG = PWM
X = np.array(X)
X = StandardScaler().fit_transform(X)
PWM = StandardScaler().fit_transform(PWM)
XX = X[:-303]
PWM = np.array(PWM)
PWMM = PWM[:-303]
X_train, X_test, PWM_train, PWM_test = train_test_split(XX, PWMM, test_size=0.2,shuffle=False)
X_Train = np.array(X_train)
X_Test = np.array(X_test)
PWM_Train = np.array(PWM_train)
PWM_Test = np.array(PWM_test)
X_train_v1 = np.vsplit(X_train,(3120/3))
X_TRAIN = np.array(X_train_v1)
X_test_v1 = np.vsplit(X_test,(780/3))
X_TEST = np.array(X_test_v1)
PWM_Train_v1 = np.vsplit(PWM_Train,(3120/3))
PWM_TRAIN = np.array(PWM_Train_v1)
PWM_Test_v1 = np.vsplit(PWM_Test,(780/3))
PWM_TEST = np.array(PWM_Test_v1)
print(PWM_TEST.shape)
X_train_v2 = tf.convert_to_tensor(X_TRAIN)
PWM_train_v2 = tf.convert_to_tensor(PWM_TRAIN)
X_test_v2 = tf.convert_to_tensor(X_TEST)
PWM_test_v2 = tf.convert_to_tensor(PWM_TEST)

LSTM_Soft9 = Sequential(name='LSTM_Soft_9s')

LSTM_Soft9.add(Input(shape=(90,2)))
#LSTM_Soft9.add(LSTM(units = 512, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft9.add(Dropout(0.1))
LSTM_Soft9.add(LSTM(units = 256, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft9.add(Dropout(0.1))
LSTM_Soft9.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_Soft9.add(Dropout(0.1))
LSTM_Soft9.add(LSTM(units = 4, return_sequences = True))
#LSTM_Soft9.add(Dropout(0.1))
LSTM_Soft9.add(tf.keras.layers.Reshape((90,4)))

LSTM_Soft9.compile(optimizer='adam',loss='mse', metrics=['accuracy'])
LSTM_Soft9.summary()

history9 = LSTM_Soft9.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True) #callbacks = [callbacks],

plt.plot(history9.history['accuracy'], label='accuracy')
plt.plot(history9.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.2, 0.8])
plt.legend(loc='lower right')

plt.plot(history9.history['loss'], label='loss')
plt.plot(history9.history['val_loss'], label = 'val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.4, 1.05])
plt.legend(loc='lower right')

plt.plot(history9.history['loss'], label='loss 9s')
plt.plot(history9.history['val_loss'], label = 'val_loss 9s')
plt.plot(history3.history['loss'], label='loss 3s')
plt.plot(history3.history['val_loss'], label = 'val_loss 3s')
plt.plot(history1.history['loss'], label='loss 1s')
plt.plot(history1.history['val_loss'], label = 'val_loss 1s')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.4, 1.05])
plt.legend(loc='lower left')

plt.plot(history9.history['accuracy'], label='accuracy 9s')
plt.plot(history9.history['val_accuracy'], label = 'val_accuracy 9s')
plt.plot(history3.history['accuracy'], label='accuracy 3s')
plt.plot(history3.history['val_accuracy'], label = 'val_accuracy 3s')
plt.plot(history1.history['accuracy'], label='accuracy 1s')
plt.plot(history1.history['val_accuracy'], label = 'val_accuracy 1s')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.2, 0.8])
plt.legend(loc='lower right')

data = pd.read_pickle("Clean_Sig_Big_NONAN_Num.pkl", compression='infer', storage_options=None)
X = data[['BX','BY']]
PWM = data[['PWM5','PWM9','PWM10','PWM11']]
PWMOG = PWM
X = np.array(X)
X = StandardScaler().fit_transform(X)
PWM = StandardScaler().fit_transform(PWM)
XX = X[:-303]
PWM = np.array(PWM)
PWMM = PWM[:-303]
X_train, X_test, PWM_train, PWM_test = train_test_split(XX, PWMM, test_size=0.2,shuffle=False)
X_Train = np.array(X_train)
X_Test = np.array(X_test)
PWM_Train = np.array(PWM_train)
PWM_Test = np.array(PWM_test)
X_train_v1 = np.vsplit(X_train,3120)
X_TRAIN = np.array(X_train_v1)
X_test_v1 = np.vsplit(X_test,780)
X_TEST = np.array(X_test_v1)
PWM_Train_v1 = np.vsplit(PWM_Train,3120)
PWM_TRAIN = np.array(PWM_Train_v1)
PWM_Test_v1 = np.vsplit(PWM_Test,780)
PWM_TEST = np.array(PWM_Test_v1)
X_train_v2 = tf.convert_to_tensor(X_TRAIN)
PWM_train_v2 = tf.convert_to_tensor(PWM_TRAIN)
X_test_v2 = tf.convert_to_tensor(X_TEST)
PWM_test_v2 = tf.convert_to_tensor(PWM_TEST)

LSTM_SoftD1 = Sequential(name='LSTM_Soft_Drop1')

LSTM_SoftD1.add(Input(shape=(30,2)))
#LSTM_Soft3.add(Dropout(0.1))
LSTM_SoftD1.add(LSTM(units = 256, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
LSTM_SoftD1.add(Dropout(0.1))
LSTM_SoftD1.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
LSTM_SoftD1.add(Dropout(0.1))
LSTM_SoftD1.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftD1.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftD1.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftD1.summary()

historyD1 = LSTM_SoftD1.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

LSTM_SoftD2 = Sequential(name='LSTM_Soft_Drop1')

LSTM_SoftD2.add(Input(shape=(30,2)))
#LSTM_Soft3.add(Dropout(0.1))
LSTM_SoftD2.add(LSTM(units = 256, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
LSTM_SoftD2.add(Dropout(0.2))
LSTM_SoftD2.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
LSTM_SoftD2.add(Dropout(0.2))
LSTM_SoftD2.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftD2.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftD2.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftD2.summary()

historyD2 = LSTM_SoftD2.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

plt.plot(history3.history['loss'], label='loss No Dropout')
plt.plot(history3.history['val_loss'], label = 'val_loss No Dropout')
plt.plot(historyD1.history['loss'], label='loss 10% Dropout')
plt.plot(historyD1.history['val_loss'], label = 'val_loss 10% Dropout')
plt.plot(historyD2.history['loss'], label='loss 20% Dropout')
plt.plot(historyD2.history['val_loss'], label = 'val_loss 20% Dropout')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.4, 1.05])
plt.legend(loc='upper right')

plt.plot(history3.history['accuracy'], label='accuracy No Dropout')
plt.plot(history3.history['val_accuracy'], label = 'val_accuracy No Dropout')
plt.plot(historyD1.history['accuracy'], label='accuracy 10% Dropout')
plt.plot(historyD1.history['val_accuracy'], label = 'val_accuracy 10% Dropout')
plt.plot(historyD2.history['accuracy'], label='accuracy 20% Dropout')
plt.plot(historyD2.history['val_accuracy'], label = 'val_accuracy 20% Dropout')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.2, 0.8])
plt.legend(loc='lower right')

LSTM_SoftL1 = Sequential(name='LSTM_Soft_1_Layer')

LSTM_SoftL1.add(Input(shape=(30,2)))
#LSTM_Soft3.add(Dropout(0.1))
LSTM_SoftL1.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftD1.add(Dropout(0.1))
#LSTM_SoftD1.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftD1.add(Dropout(0.1))
LSTM_SoftL1.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftL1.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftL1.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftL1.summary()

historyL1 = LSTM_SoftL1.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

LSTM_SoftL2 = Sequential(name='LSTM_Soft_2_Layer')

LSTM_SoftL2.add(Input(shape=(30,2)))
#LSTM_Soft3.add(Dropout(0.1))
LSTM_SoftL2.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftD1.add(Dropout(0.1))
LSTM_SoftL2.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftD1.add(Dropout(0.1))
LSTM_SoftL2.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftL2.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftL2.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftL2.summary()

historyL2 = LSTM_SoftL2.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

LSTM_SoftL3 = Sequential(name='LSTM_Soft_3_Layer')

LSTM_SoftL3.add(Input(shape=(30,2)))

LSTM_SoftL3.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))

LSTM_SoftL3.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))

LSTM_SoftL3.add(LSTM(units = 128, return_sequences = True, input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))

LSTM_SoftL3.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftL3.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftL3.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftL3.summary()

historyL3 = LSTM_SoftL3.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

plt.plot(historyL1.history['loss'], label='loss 1 Layer')
plt.plot(historyL1.history['val_loss'], label = 'val_loss 1 Layer')
plt.plot(historyL2.history['loss'], label='loss 2 Layer')
plt.plot(historyL2.history['val_loss'], label = 'val_loss 2 Layer')
plt.plot(historyL3.history['loss'], label='loss 3 Layer')
plt.plot(historyL3.history['val_loss'], label = 'val_loss 3 Layer')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.4, 1.1])
plt.legend(loc='lower left')

plt.plot(historyL1.history['accuracy'], label='accuracy 1 Layer')
plt.plot(historyL1.history['val_accuracy'], label = 'val_accuracy 1 Layer')
plt.plot(historyL2.history['accuracy'], label='accuracy 2 Layer')
plt.plot(historyL2.history['val_accuracy'], label = 'val_accuracy 2 Layer')
plt.plot(historyL3.history['accuracy'], label='accuracy 3 Layer')
plt.plot(historyL3.history['val_accuracy'], label = 'val_accuracy 3 Layer')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.2, 0.8])
plt.legend(loc='lower right')

LSTM_SoftG = Sequential(name='LSTM_Soft_Gelu1')

LSTM_SoftG.add(Input(shape=(30,2)))
LSTM_SoftG.add(LSTM(units = 256, return_sequences = True, activation='gelu', input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftR.add(layers.Activation(activations.relu))
LSTM_SoftG.add(LSTM(units = 128, return_sequences = True, activation='gelu', input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftR.add(layers.Activation(activations.relu))
LSTM_SoftG.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftG.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftG.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftG.summary()

historyG = LSTM_SoftG.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

LSTM_SoftR = Sequential(name='LSTM_Soft_Relu')

LSTM_SoftR.add(Input(shape=(30,2)))
LSTM_SoftR.add(LSTM(units = 256, return_sequences = True, activation='relu',  input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2]))) #recurrent_activation='relu',
#LSTM_SoftR.add(layers.Activation(activations.relu))
#activation='tanh',
#    recurrent_activation='sigmoid',
LSTM_SoftR.add(LSTM(units = 128, return_sequences = True, activation='relu',  input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2]))) #recurrent_activation='relu',
#LSTM_SoftR.add(layers.Activation(activations.relu))
LSTM_SoftR.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftR.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftR.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftR.summary()

historyR = LSTM_SoftR.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

LSTM_SoftS = Sequential(name='LSTM_Soft_Sig')

LSTM_SoftS.add(Input(shape=(30,2)))
LSTM_SoftS.add(LSTM(units = 256, return_sequences = True, activation='sigmoid', input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftS.add(layers.Activation(activations.sigmoid))
LSTM_SoftS.add(LSTM(units = 128, return_sequences = True, activation='sigmoid', input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftS.add(layers.Activation(activations.sigmoid))
LSTM_SoftS.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftS.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftS.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftS.summary()

historyS = LSTM_SoftS.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

LSTM_SoftT = Sequential(name='LSTM_Soft_Tanh')

LSTM_SoftT.add(Input(shape=(30,2)))
LSTM_SoftT.add(LSTM(units = 256, return_sequences = True, activation='tanh', input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftT.add(layers.Activation(activations.tanh))
LSTM_SoftT.add(LSTM(units = 128, return_sequences = True, activation='tanh', input_shape = (X_TRAIN.shape[1], X_TRAIN.shape[2])))
#LSTM_SoftT.add(layers.Activation(activations.tanh))
LSTM_SoftT.add(LSTM(units = 4, return_sequences = True))
LSTM_SoftT.add(tf.keras.layers.Reshape((30,4)))

LSTM_SoftT.compile(optimizer='adam',loss='mse',metrics=['accuracy'])
LSTM_SoftT.summary()

historyT = LSTM_SoftT.fit(X_train_v2, PWM_train_v2, batch_size = 2,  epochs = 15, validation_data=(X_test_v2, PWM_test_v2), verbose=True)

plt.plot(historyG.history['loss'], label='loss Gelu')
plt.plot(historyG.history['val_loss'], label = 'val_loss Gelu')
plt.plot(historyR.history['loss'], label='loss Relu')
plt.plot(historyR.history['val_loss'], label = 'val_loss Relu')
plt.plot(historyS.history['loss'], label='loss Sig')
plt.plot(historyS.history['val_loss'], label = 'val_loss Sig')
plt.plot(historyT.history['loss'], label='loss Tanh')
plt.plot(historyT.history['val_loss'], label = 'val_loss Tanh')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.ylim([0.4, 1.05])
plt.legend(loc='lower left')

plt.plot(historyG.history['accuracy'], label='accuracy Gelu')
plt.plot(historyG.history['val_accuracy'], label = 'val_accuracy Gelu')
plt.plot(historyR.history['accuracy'], label='accuracy Relu')
plt.plot(historyR.history['val_accuracy'], label = 'val_accuracy Relu')
plt.plot(historyS.history['accuracy'], label='accuracy Sigmoid')
plt.plot(historyS.history['val_accuracy'], label = 'val_accuracy Sigmoid')
plt.plot(historyT.history['accuracy'], label='accuracy Tanh')
plt.plot(historyT.history['val_accuracy'], label = 'val_accuracy Tanh')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.2, 0.8])
plt.legend(loc='lower right')