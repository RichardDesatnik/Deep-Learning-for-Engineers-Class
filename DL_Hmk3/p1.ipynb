{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class AirfoilDataset(Dataset):\n",
    "    '''\n",
    "    airfoil dataset: no need to modify\n",
    "    '''\n",
    "    def __init__(self, path='./airfoils'):\n",
    "        super(AirfoilDataset, self).__init__()\n",
    "        self._X = []    # x coordinates of all airfoils (shared)\n",
    "        self._Y = []    # y coordinates of all airfoils\n",
    "        self.names = [] # name of all airfoils\n",
    "        self.norm_coeff = 0\t# normalization coeff to scale y to [-1, 1]\n",
    "        airfoil_fn = [afn for afn in os.listdir(path) if afn.endswith('.dat')]\n",
    "\n",
    "        # get x coordinates of all airfoils\n",
    "        with open(os.path.join(path, airfoil_fn[0]), 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "            raw_data = f.readlines()\n",
    "            for idx in range(len(raw_data)):\n",
    "                raw_xy = raw_data[idx].split(' ')\n",
    "                while \"\" in raw_xy:\n",
    "                    raw_xy.remove(\"\")\n",
    "                self._X.append(float(raw_xy[0]))\n",
    "        self._X = np.array(self._X)\n",
    "\n",
    "        # get y coordinates of each airfoils\n",
    "        for idx, fn in enumerate(airfoil_fn):\n",
    "            with open(os.path.join(path, fn), 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "                self.names.append(fn[:-10])\n",
    "                raw_data = f.readlines()\n",
    "                airfoil = np.empty(self._X.shape[0])\n",
    "                for i in range(len(raw_data)):\n",
    "                    raw_xy = raw_data[i].split(' ')\n",
    "                    while \"\" in raw_xy:\n",
    "                        raw_xy.remove(\"\")\n",
    "                    curr_y = float(raw_xy[1])\n",
    "                    airfoil[i] = curr_y\n",
    "                    self.norm_coeff = max(self.norm_coeff, np.abs(curr_y))\n",
    "                self._Y.append(airfoil)\n",
    "\n",
    "        self._Y = np.array([airfoil / self.norm_coeff for airfoil in self._Y], dtype=np.float32)\n",
    "\n",
    "    def get_x(self):\n",
    "        '''\n",
    "        get shared x coordinates\n",
    "        '''\n",
    "        return self._X\n",
    "\n",
    "    def get_y(self):\n",
    "        '''\n",
    "        get y coordinates of all airfoils\n",
    "        '''\n",
    "        return self._Y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._Y[idx], self.names[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # build your model here\n",
    "        # your output should be of dim (batch_size, 1)\n",
    "        # since discriminator is a binary classifier\n",
    "        self.Discriminator = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # define your feedforward pass\n",
    "        foil = self.Discriminator(x)\n",
    "        return foil\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, airfoil_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        # build your model here\n",
    "        # your output should be of dim (batch_size, airfoil_dim)\n",
    "        # you can use tanh() as the activation for the last layer\n",
    "        # since y coord of airfoils range from -1 to 1\n",
    "        self.Generator = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, airfoil_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        foil = self.Generator(x)\n",
    "        return foil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (Discriminator): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (Generator): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=200, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dis = Discriminator(input_dim=200)\n",
    "gen = Generator(latent_dim=20, airfoil_dim=200)\n",
    "print(dis)\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utility functions \n",
    "Free from to add functions if needed\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_airfoils(airfoil_x, airfoil_y):\n",
    "    '''\n",
    "    plot airfoils: no need to modify \n",
    "    '''\n",
    "    idx = 0\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=4)\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            col.scatter(airfoil_x, airfoil_y[idx, :], s=0.6, c='black')\n",
    "            col.axis('off')\n",
    "            col.axis('equal')\n",
    "            idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distrminator model:\n",
      " Discriminator(\n",
      "  (Discriminator): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Generator model:\n",
      " Generator(\n",
      "  (Generator): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=200, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "Epoch: [0/200], Batch: 29, Discriminator loss: 0.678256630897522, Generator loss: 0.8806952238082886\n",
      "Epoch: [0/200], Batch: 59, Discriminator loss: 0.684645414352417, Generator loss: 0.6922539472579956\n",
      "Epoch: [0/200], Batch: 89, Discriminator loss: 0.696797251701355, Generator loss: 0.7643810510635376\n",
      "Epoch: [1/200], Batch: 29, Discriminator loss: 0.7045323252677917, Generator loss: 0.7133396863937378\n",
      "Epoch: [1/200], Batch: 59, Discriminator loss: 0.6955325603485107, Generator loss: 0.8210415840148926\n",
      "Epoch: [1/200], Batch: 89, Discriminator loss: 0.7539898157119751, Generator loss: 0.5959011316299438\n",
      "Epoch: [2/200], Batch: 29, Discriminator loss: 0.6939126253128052, Generator loss: 0.7022414207458496\n",
      "Epoch: [2/200], Batch: 59, Discriminator loss: 0.6943066120147705, Generator loss: 0.7318695187568665\n",
      "Epoch: [2/200], Batch: 89, Discriminator loss: 0.6925532221794128, Generator loss: 0.7324537634849548\n",
      "Epoch: [3/200], Batch: 29, Discriminator loss: 0.707931399345398, Generator loss: 0.6648471355438232\n",
      "Epoch: [3/200], Batch: 59, Discriminator loss: 0.6879807114601135, Generator loss: 0.7463458180427551\n",
      "Epoch: [3/200], Batch: 89, Discriminator loss: 0.6808743476867676, Generator loss: 0.7150298953056335\n",
      "Epoch: [4/200], Batch: 29, Discriminator loss: 0.6853587031364441, Generator loss: 0.6857665777206421\n",
      "Epoch: [4/200], Batch: 59, Discriminator loss: 0.6678876876831055, Generator loss: 0.75937420129776\n",
      "Epoch: [4/200], Batch: 89, Discriminator loss: 0.6992270946502686, Generator loss: 0.6990524530410767\n",
      "Epoch: [5/200], Batch: 29, Discriminator loss: 0.6927427053451538, Generator loss: 0.7033112645149231\n",
      "Epoch: [5/200], Batch: 59, Discriminator loss: 0.6965545415878296, Generator loss: 0.6820192933082581\n",
      "Epoch: [5/200], Batch: 89, Discriminator loss: 0.6738142967224121, Generator loss: 0.8213410377502441\n",
      "Epoch: [6/200], Batch: 29, Discriminator loss: 0.6903287768363953, Generator loss: 0.7152675986289978\n",
      "Epoch: [6/200], Batch: 59, Discriminator loss: 0.6929344534873962, Generator loss: 0.6953267455101013\n",
      "Epoch: [6/200], Batch: 89, Discriminator loss: 0.6941551566123962, Generator loss: 0.7079192399978638\n",
      "Epoch: [7/200], Batch: 29, Discriminator loss: 0.703304648399353, Generator loss: 0.6825825572013855\n",
      "Epoch: [7/200], Batch: 59, Discriminator loss: 0.7042167782783508, Generator loss: 0.6973809003829956\n",
      "Epoch: [7/200], Batch: 89, Discriminator loss: 0.7022850513458252, Generator loss: 0.6939176917076111\n",
      "Epoch: [8/200], Batch: 29, Discriminator loss: 0.6913242936134338, Generator loss: 0.7004830241203308\n",
      "Epoch: [8/200], Batch: 59, Discriminator loss: 0.6864219903945923, Generator loss: 0.6603415608406067\n",
      "Epoch: [8/200], Batch: 89, Discriminator loss: 0.6890636682510376, Generator loss: 0.7634388208389282\n",
      "Epoch: [9/200], Batch: 29, Discriminator loss: 0.6867314577102661, Generator loss: 0.7521592974662781\n",
      "Epoch: [9/200], Batch: 59, Discriminator loss: 0.6943720579147339, Generator loss: 0.7169034481048584\n",
      "Epoch: [9/200], Batch: 89, Discriminator loss: 0.6626995801925659, Generator loss: 0.7892475128173828\n",
      "Epoch: [10/200], Batch: 29, Discriminator loss: 0.6977865099906921, Generator loss: 0.7296731472015381\n",
      "Epoch: [10/200], Batch: 59, Discriminator loss: 0.6942751407623291, Generator loss: 0.6973819136619568\n",
      "Epoch: [10/200], Batch: 89, Discriminator loss: 0.6967009902000427, Generator loss: 0.6874402761459351\n",
      "Epoch: [11/200], Batch: 29, Discriminator loss: 0.6909022331237793, Generator loss: 0.6948104500770569\n",
      "Epoch: [11/200], Batch: 59, Discriminator loss: 0.7386163473129272, Generator loss: 0.6251049041748047\n",
      "Epoch: [11/200], Batch: 89, Discriminator loss: 0.6985428333282471, Generator loss: 0.6996874809265137\n",
      "Epoch: [12/200], Batch: 29, Discriminator loss: 0.7120699882507324, Generator loss: 0.7129818797111511\n",
      "Epoch: [12/200], Batch: 59, Discriminator loss: 0.6661108732223511, Generator loss: 0.8414005041122437\n",
      "Epoch: [12/200], Batch: 89, Discriminator loss: 0.706112265586853, Generator loss: 0.828129768371582\n",
      "Epoch: [13/200], Batch: 29, Discriminator loss: 0.6916755437850952, Generator loss: 0.6949525475502014\n",
      "Epoch: [13/200], Batch: 59, Discriminator loss: 0.6941577196121216, Generator loss: 0.6633861660957336\n",
      "Epoch: [13/200], Batch: 89, Discriminator loss: 0.7190340161323547, Generator loss: 0.7445154786109924\n",
      "Epoch: [14/200], Batch: 29, Discriminator loss: 0.6833746433258057, Generator loss: 0.8423416614532471\n",
      "Epoch: [14/200], Batch: 59, Discriminator loss: 0.7065494060516357, Generator loss: 0.7499139904975891\n",
      "Epoch: [14/200], Batch: 89, Discriminator loss: 0.6973932981491089, Generator loss: 0.7272128462791443\n",
      "Epoch: [15/200], Batch: 29, Discriminator loss: 0.6945944428443909, Generator loss: 0.7248545289039612\n",
      "Epoch: [15/200], Batch: 59, Discriminator loss: 0.6942206621170044, Generator loss: 0.6824432611465454\n",
      "Epoch: [15/200], Batch: 89, Discriminator loss: 0.6851636171340942, Generator loss: 0.6817216873168945\n",
      "Epoch: [16/200], Batch: 29, Discriminator loss: 0.6874881982803345, Generator loss: 0.6995221972465515\n",
      "Epoch: [16/200], Batch: 59, Discriminator loss: 0.6232395172119141, Generator loss: 0.8259536623954773\n",
      "Epoch: [16/200], Batch: 89, Discriminator loss: 0.6961929202079773, Generator loss: 0.7049633264541626\n",
      "Epoch: [17/200], Batch: 29, Discriminator loss: 0.6955339908599854, Generator loss: 0.6876041293144226\n",
      "Epoch: [17/200], Batch: 59, Discriminator loss: 0.6893320679664612, Generator loss: 0.7091457843780518\n",
      "Epoch: [17/200], Batch: 89, Discriminator loss: 0.7080483436584473, Generator loss: 0.7067117691040039\n",
      "Epoch: [18/200], Batch: 29, Discriminator loss: 0.700065553188324, Generator loss: 0.7335917949676514\n",
      "Epoch: [18/200], Batch: 59, Discriminator loss: 0.6990622282028198, Generator loss: 0.7235969305038452\n",
      "Epoch: [18/200], Batch: 89, Discriminator loss: 0.6910923719406128, Generator loss: 0.7291548252105713\n",
      "Epoch: [19/200], Batch: 29, Discriminator loss: 0.6879227757453918, Generator loss: 0.8119022846221924\n",
      "Epoch: [19/200], Batch: 59, Discriminator loss: 0.6948012113571167, Generator loss: 0.7040356397628784\n",
      "Epoch: [19/200], Batch: 89, Discriminator loss: 0.6916275024414062, Generator loss: 0.7110967040061951\n",
      "Epoch: [20/200], Batch: 29, Discriminator loss: 0.6911410689353943, Generator loss: 0.6966025233268738\n",
      "Epoch: [20/200], Batch: 59, Discriminator loss: 0.6713912487030029, Generator loss: 0.6988585591316223\n",
      "Epoch: [20/200], Batch: 89, Discriminator loss: 0.6823444366455078, Generator loss: 0.9193699359893799\n",
      "Epoch: [21/200], Batch: 29, Discriminator loss: 0.6936888098716736, Generator loss: 0.6738941073417664\n",
      "Epoch: [21/200], Batch: 59, Discriminator loss: 0.6972005367279053, Generator loss: 0.712607741355896\n",
      "Epoch: [21/200], Batch: 89, Discriminator loss: 0.6906571388244629, Generator loss: 0.6743609309196472\n",
      "Epoch: [22/200], Batch: 29, Discriminator loss: 0.6939694881439209, Generator loss: 0.6963867545127869\n",
      "Epoch: [22/200], Batch: 59, Discriminator loss: 0.6951172947883606, Generator loss: 0.7030678987503052\n",
      "Epoch: [22/200], Batch: 89, Discriminator loss: 0.6926743984222412, Generator loss: 0.704635500907898\n",
      "Epoch: [23/200], Batch: 29, Discriminator loss: 0.6924934387207031, Generator loss: 0.6990726590156555\n",
      "Epoch: [23/200], Batch: 59, Discriminator loss: 0.6854022145271301, Generator loss: 0.680070698261261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23/200], Batch: 89, Discriminator loss: 0.6989209651947021, Generator loss: 0.6837399005889893\n",
      "Epoch: [24/200], Batch: 29, Discriminator loss: 0.6867782473564148, Generator loss: 0.709461510181427\n",
      "Epoch: [24/200], Batch: 59, Discriminator loss: 0.693949282169342, Generator loss: 0.677216112613678\n",
      "Epoch: [24/200], Batch: 89, Discriminator loss: 0.6951442956924438, Generator loss: 0.711103081703186\n",
      "Epoch: [25/200], Batch: 29, Discriminator loss: 0.692836582660675, Generator loss: 0.6950049996376038\n",
      "Epoch: [25/200], Batch: 59, Discriminator loss: 0.6892222762107849, Generator loss: 0.6889173984527588\n",
      "Epoch: [25/200], Batch: 89, Discriminator loss: 0.7565250992774963, Generator loss: 0.5933141708374023\n",
      "Epoch: [26/200], Batch: 29, Discriminator loss: 0.6937897205352783, Generator loss: 0.705389142036438\n",
      "Epoch: [26/200], Batch: 59, Discriminator loss: 0.7033146023750305, Generator loss: 0.6609103083610535\n",
      "Epoch: [26/200], Batch: 89, Discriminator loss: 0.6893943548202515, Generator loss: 0.7682037949562073\n",
      "Epoch: [27/200], Batch: 29, Discriminator loss: 0.6942675113677979, Generator loss: 0.7142446041107178\n",
      "Epoch: [27/200], Batch: 59, Discriminator loss: 0.6627464890480042, Generator loss: 0.7057242393493652\n",
      "Epoch: [27/200], Batch: 89, Discriminator loss: 0.7326803207397461, Generator loss: 0.6345412135124207\n",
      "Epoch: [28/200], Batch: 29, Discriminator loss: 0.6795021295547485, Generator loss: 0.6229491829872131\n",
      "Epoch: [28/200], Batch: 59, Discriminator loss: 0.7047947645187378, Generator loss: 0.7102302312850952\n",
      "Epoch: [28/200], Batch: 89, Discriminator loss: 0.6975959539413452, Generator loss: 0.670742392539978\n",
      "Epoch: [29/200], Batch: 29, Discriminator loss: 0.6932442784309387, Generator loss: 0.7055181860923767\n",
      "Epoch: [29/200], Batch: 59, Discriminator loss: 0.6939306259155273, Generator loss: 0.6720535159111023\n",
      "Epoch: [29/200], Batch: 89, Discriminator loss: 0.6912057995796204, Generator loss: 0.6914700865745544\n",
      "Epoch: [30/200], Batch: 29, Discriminator loss: 0.6366196870803833, Generator loss: 0.640332043170929\n",
      "Epoch: [30/200], Batch: 59, Discriminator loss: 0.7095428109169006, Generator loss: 0.7985380291938782\n",
      "Epoch: [30/200], Batch: 89, Discriminator loss: 0.6973321437835693, Generator loss: 0.8352199792861938\n",
      "Epoch: [31/200], Batch: 29, Discriminator loss: 0.6998097896575928, Generator loss: 0.64103764295578\n",
      "Epoch: [31/200], Batch: 59, Discriminator loss: 0.6968086957931519, Generator loss: 0.7242736220359802\n",
      "Epoch: [31/200], Batch: 89, Discriminator loss: 0.6894854307174683, Generator loss: 0.6531331539154053\n",
      "Epoch: [32/200], Batch: 29, Discriminator loss: 0.7128227949142456, Generator loss: 0.7442492246627808\n",
      "Epoch: [32/200], Batch: 59, Discriminator loss: 0.6034283638000488, Generator loss: 0.7397709488868713\n",
      "Epoch: [32/200], Batch: 89, Discriminator loss: 1.1401556730270386, Generator loss: 1.1410878896713257\n",
      "Epoch: [33/200], Batch: 29, Discriminator loss: 0.667049765586853, Generator loss: 0.6487574577331543\n",
      "Epoch: [33/200], Batch: 59, Discriminator loss: 0.7092939019203186, Generator loss: 0.7970640063285828\n",
      "Epoch: [33/200], Batch: 89, Discriminator loss: 0.6498927474021912, Generator loss: 0.7472254633903503\n",
      "Epoch: [34/200], Batch: 29, Discriminator loss: 0.6798242330551147, Generator loss: 0.8925418853759766\n",
      "Epoch: [34/200], Batch: 59, Discriminator loss: 0.6668978333473206, Generator loss: 0.6783947944641113\n",
      "Epoch: [34/200], Batch: 89, Discriminator loss: 0.7014062404632568, Generator loss: 0.7413724660873413\n",
      "Epoch: [35/200], Batch: 29, Discriminator loss: 0.6946694850921631, Generator loss: 0.6781505346298218\n",
      "Epoch: [35/200], Batch: 59, Discriminator loss: 0.6902347207069397, Generator loss: 0.7079074382781982\n",
      "Epoch: [35/200], Batch: 89, Discriminator loss: 0.6913543939590454, Generator loss: 0.7248983383178711\n",
      "Epoch: [36/200], Batch: 29, Discriminator loss: 0.6922366619110107, Generator loss: 0.7805730104446411\n",
      "Epoch: [36/200], Batch: 59, Discriminator loss: 0.6904523372650146, Generator loss: 0.7228909134864807\n",
      "Epoch: [36/200], Batch: 89, Discriminator loss: 0.6936320662498474, Generator loss: 0.680506706237793\n",
      "Epoch: [37/200], Batch: 29, Discriminator loss: 0.6928668022155762, Generator loss: 0.7140293121337891\n",
      "Epoch: [37/200], Batch: 59, Discriminator loss: 0.690546452999115, Generator loss: 0.6804062128067017\n",
      "Epoch: [37/200], Batch: 89, Discriminator loss: 0.6917018294334412, Generator loss: 0.7038637399673462\n",
      "Epoch: [38/200], Batch: 29, Discriminator loss: 0.6935852766036987, Generator loss: 0.6478163003921509\n",
      "Epoch: [38/200], Batch: 59, Discriminator loss: 0.6908594369888306, Generator loss: 0.7179575562477112\n",
      "Epoch: [38/200], Batch: 89, Discriminator loss: 0.6907336711883545, Generator loss: 0.6647263765335083\n",
      "Epoch: [39/200], Batch: 29, Discriminator loss: 0.692730724811554, Generator loss: 0.6641727685928345\n",
      "Epoch: [39/200], Batch: 59, Discriminator loss: 0.6940618753433228, Generator loss: 0.6952083110809326\n",
      "Epoch: [39/200], Batch: 89, Discriminator loss: 0.695095956325531, Generator loss: 0.7106185555458069\n",
      "Epoch: [40/200], Batch: 29, Discriminator loss: 0.6968382000923157, Generator loss: 0.700532078742981\n",
      "Epoch: [40/200], Batch: 59, Discriminator loss: 0.6978791952133179, Generator loss: 0.6919749975204468\n",
      "Epoch: [40/200], Batch: 89, Discriminator loss: 0.6895831823348999, Generator loss: 0.659880518913269\n",
      "Epoch: [41/200], Batch: 29, Discriminator loss: 0.6893260478973389, Generator loss: 0.6544625759124756\n",
      "Epoch: [41/200], Batch: 59, Discriminator loss: 0.6878110766410828, Generator loss: 0.6587401628494263\n",
      "Epoch: [41/200], Batch: 89, Discriminator loss: 0.6923120021820068, Generator loss: 0.6596435904502869\n",
      "Epoch: [42/200], Batch: 29, Discriminator loss: 0.6923618912696838, Generator loss: 0.6923434734344482\n",
      "Epoch: [42/200], Batch: 59, Discriminator loss: 0.6907877326011658, Generator loss: 0.7014908790588379\n",
      "Epoch: [42/200], Batch: 89, Discriminator loss: 0.6898663640022278, Generator loss: 0.6806395649909973\n",
      "Epoch: [43/200], Batch: 29, Discriminator loss: 0.6985424757003784, Generator loss: 0.6746418476104736\n",
      "Epoch: [43/200], Batch: 59, Discriminator loss: 0.6941832304000854, Generator loss: 0.7350819110870361\n",
      "Epoch: [43/200], Batch: 89, Discriminator loss: 0.6924401521682739, Generator loss: 0.7245492935180664\n",
      "Epoch: [44/200], Batch: 29, Discriminator loss: 0.6982455253601074, Generator loss: 0.7064151167869568\n",
      "Epoch: [44/200], Batch: 59, Discriminator loss: 0.6929250359535217, Generator loss: 0.7021618485450745\n",
      "Epoch: [44/200], Batch: 89, Discriminator loss: 0.6943217515945435, Generator loss: 0.7156692743301392\n",
      "Epoch: [45/200], Batch: 29, Discriminator loss: 0.6927839517593384, Generator loss: 0.6718786954879761\n",
      "Epoch: [45/200], Batch: 59, Discriminator loss: 0.6910852193832397, Generator loss: 0.7321490049362183\n",
      "Epoch: [45/200], Batch: 89, Discriminator loss: 0.696571409702301, Generator loss: 0.6624058485031128\n",
      "Epoch: [46/200], Batch: 29, Discriminator loss: 0.6743526458740234, Generator loss: 0.7178875803947449\n",
      "Epoch: [46/200], Batch: 59, Discriminator loss: 0.6893300414085388, Generator loss: 0.6812276840209961\n",
      "Epoch: [46/200], Batch: 89, Discriminator loss: 0.6924968957901001, Generator loss: 0.6931356191635132\n",
      "Epoch: [47/200], Batch: 29, Discriminator loss: 0.6917572617530823, Generator loss: 0.6958099603652954\n",
      "Epoch: [47/200], Batch: 59, Discriminator loss: 0.6915006637573242, Generator loss: 0.6972981691360474\n",
      "Epoch: [47/200], Batch: 89, Discriminator loss: 0.691115140914917, Generator loss: 0.7119208574295044\n",
      "Epoch: [48/200], Batch: 29, Discriminator loss: 0.6912479996681213, Generator loss: 0.69394850730896\n",
      "Epoch: [48/200], Batch: 59, Discriminator loss: 0.6925696730613708, Generator loss: 0.7130364775657654\n",
      "Epoch: [48/200], Batch: 89, Discriminator loss: 0.6875463128089905, Generator loss: 0.7288413047790527\n",
      "Epoch: [49/200], Batch: 29, Discriminator loss: 0.6962355971336365, Generator loss: 0.7423686385154724\n",
      "Epoch: [49/200], Batch: 59, Discriminator loss: 0.6933205723762512, Generator loss: 0.7154565453529358\n",
      "Epoch: [49/200], Batch: 89, Discriminator loss: 0.6908339262008667, Generator loss: 0.7088988423347473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50/200], Batch: 29, Discriminator loss: 0.6894214153289795, Generator loss: 0.7049660682678223\n",
      "Epoch: [50/200], Batch: 59, Discriminator loss: 0.6895833611488342, Generator loss: 0.7284941673278809\n",
      "Epoch: [50/200], Batch: 89, Discriminator loss: 0.6947381496429443, Generator loss: 0.6893672943115234\n",
      "Epoch: [51/200], Batch: 29, Discriminator loss: 0.6928911209106445, Generator loss: 0.744413435459137\n",
      "Epoch: [51/200], Batch: 59, Discriminator loss: 0.6910261511802673, Generator loss: 0.6991360187530518\n",
      "Epoch: [51/200], Batch: 89, Discriminator loss: 0.6915515065193176, Generator loss: 0.6894159913063049\n",
      "Epoch: [52/200], Batch: 29, Discriminator loss: 0.6953915357589722, Generator loss: 0.6254881620407104\n",
      "Epoch: [52/200], Batch: 59, Discriminator loss: 0.6930288076400757, Generator loss: 0.6713458299636841\n",
      "Epoch: [52/200], Batch: 89, Discriminator loss: 0.6926237344741821, Generator loss: 0.6889263391494751\n",
      "Epoch: [53/200], Batch: 29, Discriminator loss: 0.6902390718460083, Generator loss: 0.7256593108177185\n",
      "Epoch: [53/200], Batch: 59, Discriminator loss: 0.6971216201782227, Generator loss: 0.703148603439331\n",
      "Epoch: [53/200], Batch: 89, Discriminator loss: 0.6907845735549927, Generator loss: 0.7199247479438782\n",
      "Epoch: [54/200], Batch: 29, Discriminator loss: 0.6885969042778015, Generator loss: 0.6915810704231262\n",
      "Epoch: [54/200], Batch: 59, Discriminator loss: 0.6868317127227783, Generator loss: 0.7734615206718445\n",
      "Epoch: [54/200], Batch: 89, Discriminator loss: 0.7019081711769104, Generator loss: 0.6630143523216248\n",
      "Epoch: [55/200], Batch: 29, Discriminator loss: 0.6941776871681213, Generator loss: 0.6938027143478394\n",
      "Epoch: [55/200], Batch: 59, Discriminator loss: 0.6886434555053711, Generator loss: 0.7228105068206787\n",
      "Epoch: [55/200], Batch: 89, Discriminator loss: 0.6920995116233826, Generator loss: 0.6725609302520752\n",
      "Epoch: [56/200], Batch: 29, Discriminator loss: 0.6977439522743225, Generator loss: 0.7280918955802917\n",
      "Epoch: [56/200], Batch: 59, Discriminator loss: 0.6928553581237793, Generator loss: 0.7156067490577698\n",
      "Epoch: [56/200], Batch: 89, Discriminator loss: 0.6963724493980408, Generator loss: 0.6976447701454163\n",
      "Epoch: [57/200], Batch: 29, Discriminator loss: 0.6939364671707153, Generator loss: 0.6957552433013916\n",
      "Epoch: [57/200], Batch: 59, Discriminator loss: 0.6930475831031799, Generator loss: 0.7101852893829346\n",
      "Epoch: [57/200], Batch: 89, Discriminator loss: 0.6938970685005188, Generator loss: 0.6955162882804871\n",
      "Epoch: [58/200], Batch: 29, Discriminator loss: 0.695732593536377, Generator loss: 0.7152010202407837\n",
      "Epoch: [58/200], Batch: 59, Discriminator loss: 0.6923307776451111, Generator loss: 0.7040124535560608\n",
      "Epoch: [58/200], Batch: 89, Discriminator loss: 0.6911811828613281, Generator loss: 0.7058565020561218\n",
      "Epoch: [59/200], Batch: 29, Discriminator loss: 0.6909782886505127, Generator loss: 0.72651207447052\n",
      "Epoch: [59/200], Batch: 59, Discriminator loss: 0.6900067329406738, Generator loss: 0.659942626953125\n",
      "Epoch: [59/200], Batch: 89, Discriminator loss: 0.6880979537963867, Generator loss: 0.740626871585846\n",
      "Epoch: [60/200], Batch: 29, Discriminator loss: 0.6954443454742432, Generator loss: 0.6712297201156616\n",
      "Epoch: [60/200], Batch: 59, Discriminator loss: 0.6998926997184753, Generator loss: 0.6735098958015442\n",
      "Epoch: [60/200], Batch: 89, Discriminator loss: 0.7256407737731934, Generator loss: 0.7990602850914001\n",
      "Epoch: [61/200], Batch: 29, Discriminator loss: 0.6990534067153931, Generator loss: 0.6383844614028931\n",
      "Epoch: [61/200], Batch: 59, Discriminator loss: 0.697894811630249, Generator loss: 0.6835479140281677\n",
      "Epoch: [61/200], Batch: 89, Discriminator loss: 0.6927823424339294, Generator loss: 0.6899720430374146\n",
      "Epoch: [62/200], Batch: 29, Discriminator loss: 0.6886045336723328, Generator loss: 0.6859212517738342\n",
      "Epoch: [62/200], Batch: 59, Discriminator loss: 0.6949827075004578, Generator loss: 0.7126901149749756\n",
      "Epoch: [62/200], Batch: 89, Discriminator loss: 0.6923337578773499, Generator loss: 0.7062867879867554\n",
      "Epoch: [63/200], Batch: 29, Discriminator loss: 0.6918742060661316, Generator loss: 0.6809756755828857\n",
      "Epoch: [63/200], Batch: 59, Discriminator loss: 0.6857889890670776, Generator loss: 0.6639305949211121\n",
      "Epoch: [63/200], Batch: 89, Discriminator loss: 0.7471533417701721, Generator loss: 0.7389683127403259\n",
      "Epoch: [64/200], Batch: 29, Discriminator loss: 0.6919675469398499, Generator loss: 0.6687625646591187\n",
      "Epoch: [64/200], Batch: 59, Discriminator loss: 0.6870656609535217, Generator loss: 0.7393707036972046\n",
      "Epoch: [64/200], Batch: 89, Discriminator loss: 0.6884293556213379, Generator loss: 0.6938424110412598\n",
      "Epoch: [65/200], Batch: 29, Discriminator loss: 0.6919004321098328, Generator loss: 0.7214701175689697\n",
      "Epoch: [65/200], Batch: 59, Discriminator loss: 0.6928691864013672, Generator loss: 0.6788143515586853\n",
      "Epoch: [65/200], Batch: 89, Discriminator loss: 0.6939939260482788, Generator loss: 0.6985056400299072\n",
      "Epoch: [66/200], Batch: 29, Discriminator loss: 0.693218469619751, Generator loss: 0.7329909205436707\n",
      "Epoch: [66/200], Batch: 59, Discriminator loss: 0.6938889622688293, Generator loss: 0.7027527093887329\n",
      "Epoch: [66/200], Batch: 89, Discriminator loss: 0.6889810562133789, Generator loss: 0.7134028077125549\n",
      "Epoch: [67/200], Batch: 29, Discriminator loss: 0.6806033253669739, Generator loss: 0.6587237119674683\n",
      "Epoch: [67/200], Batch: 59, Discriminator loss: 0.6945979595184326, Generator loss: 0.7209553122520447\n",
      "Epoch: [67/200], Batch: 89, Discriminator loss: 0.685983419418335, Generator loss: 0.7015021443367004\n",
      "Epoch: [68/200], Batch: 29, Discriminator loss: 0.6937789916992188, Generator loss: 0.6933561563491821\n",
      "Epoch: [68/200], Batch: 59, Discriminator loss: 0.6906206011772156, Generator loss: 0.666527271270752\n",
      "Epoch: [68/200], Batch: 89, Discriminator loss: 0.6870620250701904, Generator loss: 0.6550104022026062\n",
      "Epoch: [69/200], Batch: 29, Discriminator loss: 0.6937581300735474, Generator loss: 0.6536829471588135\n",
      "Epoch: [69/200], Batch: 59, Discriminator loss: 0.7334284782409668, Generator loss: 0.6695163249969482\n",
      "Epoch: [69/200], Batch: 89, Discriminator loss: 0.6814903020858765, Generator loss: 0.6582735776901245\n",
      "Epoch: [70/200], Batch: 29, Discriminator loss: 0.6911823153495789, Generator loss: 0.6531896591186523\n",
      "Epoch: [70/200], Batch: 59, Discriminator loss: 0.7100163102149963, Generator loss: 0.7085402607917786\n",
      "Epoch: [70/200], Batch: 89, Discriminator loss: 0.6927043795585632, Generator loss: 0.7133073806762695\n",
      "Epoch: [71/200], Batch: 29, Discriminator loss: 0.6935513019561768, Generator loss: 0.6984381675720215\n",
      "Epoch: [71/200], Batch: 59, Discriminator loss: 0.6874257922172546, Generator loss: 0.6929428577423096\n",
      "Epoch: [71/200], Batch: 89, Discriminator loss: 0.701519250869751, Generator loss: 0.6510287523269653\n",
      "Epoch: [72/200], Batch: 29, Discriminator loss: 0.690567135810852, Generator loss: 0.6995787024497986\n",
      "Epoch: [72/200], Batch: 59, Discriminator loss: 0.6907234787940979, Generator loss: 0.7361215353012085\n",
      "Epoch: [72/200], Batch: 89, Discriminator loss: 0.6835601329803467, Generator loss: 0.7249367833137512\n",
      "Epoch: [73/200], Batch: 29, Discriminator loss: 0.6911169290542603, Generator loss: 0.7103636860847473\n",
      "Epoch: [73/200], Batch: 59, Discriminator loss: 0.6970279812812805, Generator loss: 0.6977836489677429\n",
      "Epoch: [73/200], Batch: 89, Discriminator loss: 0.6992654204368591, Generator loss: 0.6610943078994751\n",
      "Epoch: [74/200], Batch: 29, Discriminator loss: 0.686576247215271, Generator loss: 0.681011974811554\n",
      "Epoch: [74/200], Batch: 59, Discriminator loss: 0.688620924949646, Generator loss: 0.6714736819267273\n",
      "Epoch: [74/200], Batch: 89, Discriminator loss: 0.6935979723930359, Generator loss: 0.7013400793075562\n",
      "Epoch: [75/200], Batch: 29, Discriminator loss: 0.6912299990653992, Generator loss: 0.711534321308136\n",
      "Epoch: [75/200], Batch: 59, Discriminator loss: 0.6864405274391174, Generator loss: 0.7440139055252075\n",
      "Epoch: [75/200], Batch: 89, Discriminator loss: 0.6861346364021301, Generator loss: 0.6685816049575806\n",
      "Epoch: [76/200], Batch: 29, Discriminator loss: 0.6986437439918518, Generator loss: 0.7099107503890991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76/200], Batch: 59, Discriminator loss: 0.7073057889938354, Generator loss: 0.7975863218307495\n",
      "Epoch: [76/200], Batch: 89, Discriminator loss: 0.6930000185966492, Generator loss: 0.6897712349891663\n",
      "Epoch: [77/200], Batch: 29, Discriminator loss: 0.6902086734771729, Generator loss: 0.7049612402915955\n",
      "Epoch: [77/200], Batch: 59, Discriminator loss: 0.6625442504882812, Generator loss: 0.6610639095306396\n",
      "Epoch: [77/200], Batch: 89, Discriminator loss: 0.6873253583908081, Generator loss: 0.6781540513038635\n",
      "Epoch: [78/200], Batch: 29, Discriminator loss: 0.7027275562286377, Generator loss: 0.7622084617614746\n",
      "Epoch: [78/200], Batch: 59, Discriminator loss: 0.6927762031555176, Generator loss: 0.6823703050613403\n",
      "Epoch: [78/200], Batch: 89, Discriminator loss: 0.694085955619812, Generator loss: 0.736444354057312\n",
      "Epoch: [79/200], Batch: 29, Discriminator loss: 0.6910211443901062, Generator loss: 0.7056795358657837\n",
      "Epoch: [79/200], Batch: 59, Discriminator loss: 0.6891957521438599, Generator loss: 0.6179738640785217\n",
      "Epoch: [79/200], Batch: 89, Discriminator loss: 0.6844388246536255, Generator loss: 0.7020718455314636\n",
      "Epoch: [80/200], Batch: 29, Discriminator loss: 0.6925429105758667, Generator loss: 0.6646571159362793\n",
      "Epoch: [80/200], Batch: 59, Discriminator loss: 0.6903719902038574, Generator loss: 0.7009133100509644\n",
      "Epoch: [80/200], Batch: 89, Discriminator loss: 0.6968784928321838, Generator loss: 0.7374850511550903\n",
      "Epoch: [81/200], Batch: 29, Discriminator loss: 0.6955430507659912, Generator loss: 0.7628567218780518\n",
      "Epoch: [81/200], Batch: 59, Discriminator loss: 0.7011969089508057, Generator loss: 0.6607857942581177\n",
      "Epoch: [81/200], Batch: 89, Discriminator loss: 0.6875600218772888, Generator loss: 0.667081892490387\n",
      "Epoch: [82/200], Batch: 29, Discriminator loss: 0.6910948157310486, Generator loss: 0.6719108819961548\n",
      "Epoch: [82/200], Batch: 59, Discriminator loss: 0.6909506916999817, Generator loss: 0.6687107682228088\n",
      "Epoch: [82/200], Batch: 89, Discriminator loss: 0.6856023669242859, Generator loss: 0.6588892936706543\n",
      "Epoch: [83/200], Batch: 29, Discriminator loss: 0.7044849991798401, Generator loss: 0.7295668721199036\n",
      "Epoch: [83/200], Batch: 59, Discriminator loss: 0.6776999831199646, Generator loss: 0.740343451499939\n",
      "Epoch: [83/200], Batch: 89, Discriminator loss: 0.6928481459617615, Generator loss: 0.7318428754806519\n",
      "Epoch: [84/200], Batch: 29, Discriminator loss: 0.6881495118141174, Generator loss: 0.717515230178833\n",
      "Epoch: [84/200], Batch: 59, Discriminator loss: 0.7012229561805725, Generator loss: 0.7432237267494202\n",
      "Epoch: [84/200], Batch: 89, Discriminator loss: 0.6453795433044434, Generator loss: 0.6581501960754395\n",
      "Epoch: [85/200], Batch: 29, Discriminator loss: 0.6851399540901184, Generator loss: 0.6924530267715454\n",
      "Epoch: [85/200], Batch: 59, Discriminator loss: 0.6718579530715942, Generator loss: 0.7047275900840759\n",
      "Epoch: [85/200], Batch: 89, Discriminator loss: 0.6956819295883179, Generator loss: 0.699971616268158\n",
      "Epoch: [86/200], Batch: 29, Discriminator loss: 0.6943284869194031, Generator loss: 0.7359835505485535\n",
      "Epoch: [86/200], Batch: 59, Discriminator loss: 0.6987082958221436, Generator loss: 0.701461672782898\n",
      "Epoch: [86/200], Batch: 89, Discriminator loss: 0.6933305859565735, Generator loss: 0.681990385055542\n",
      "Epoch: [87/200], Batch: 29, Discriminator loss: 0.6922928094863892, Generator loss: 0.7071812152862549\n",
      "Epoch: [87/200], Batch: 59, Discriminator loss: 0.68022221326828, Generator loss: 0.7613804340362549\n",
      "Epoch: [87/200], Batch: 89, Discriminator loss: 0.694850742816925, Generator loss: 0.7087111473083496\n",
      "Epoch: [88/200], Batch: 29, Discriminator loss: 0.6912802457809448, Generator loss: 0.7572519183158875\n",
      "Epoch: [88/200], Batch: 59, Discriminator loss: 0.6905602812767029, Generator loss: 0.6476229429244995\n",
      "Epoch: [88/200], Batch: 89, Discriminator loss: 0.6927955746650696, Generator loss: 0.7644779086112976\n",
      "Epoch: [89/200], Batch: 29, Discriminator loss: 0.6867409944534302, Generator loss: 0.717833399772644\n",
      "Epoch: [89/200], Batch: 59, Discriminator loss: 0.6898353099822998, Generator loss: 0.6673192977905273\n",
      "Epoch: [89/200], Batch: 89, Discriminator loss: 0.6914566159248352, Generator loss: 0.6871828436851501\n",
      "Epoch: [90/200], Batch: 29, Discriminator loss: 0.6983766555786133, Generator loss: 0.7062728404998779\n",
      "Epoch: [90/200], Batch: 59, Discriminator loss: 0.6969918608665466, Generator loss: 0.7034265995025635\n",
      "Epoch: [90/200], Batch: 89, Discriminator loss: 0.6724096536636353, Generator loss: 0.7328786849975586\n",
      "Epoch: [91/200], Batch: 29, Discriminator loss: 0.6877173185348511, Generator loss: 0.7196569442749023\n",
      "Epoch: [91/200], Batch: 59, Discriminator loss: 0.6614164710044861, Generator loss: 0.676303505897522\n",
      "Epoch: [91/200], Batch: 89, Discriminator loss: 0.7272164821624756, Generator loss: 0.6995713114738464\n",
      "Epoch: [92/200], Batch: 29, Discriminator loss: 0.7002956867218018, Generator loss: 0.7238509058952332\n",
      "Epoch: [92/200], Batch: 59, Discriminator loss: 0.68628990650177, Generator loss: 0.6716407537460327\n",
      "Epoch: [92/200], Batch: 89, Discriminator loss: 0.6978906393051147, Generator loss: 0.6320294737815857\n",
      "Epoch: [93/200], Batch: 29, Discriminator loss: 0.6980117559432983, Generator loss: 0.7472761869430542\n",
      "Epoch: [93/200], Batch: 59, Discriminator loss: 0.7157034873962402, Generator loss: 0.6946427226066589\n",
      "Epoch: [93/200], Batch: 89, Discriminator loss: 0.7015112042427063, Generator loss: 0.684928297996521\n",
      "Epoch: [94/200], Batch: 29, Discriminator loss: 0.7015063762664795, Generator loss: 0.6733894348144531\n",
      "Epoch: [94/200], Batch: 59, Discriminator loss: 0.7136175036430359, Generator loss: 0.7190951108932495\n",
      "Epoch: [94/200], Batch: 89, Discriminator loss: 0.7134420275688171, Generator loss: 0.7372006177902222\n",
      "Epoch: [95/200], Batch: 29, Discriminator loss: 0.6731802225112915, Generator loss: 0.6913623809814453\n",
      "Epoch: [95/200], Batch: 59, Discriminator loss: 0.6886960864067078, Generator loss: 0.7045959830284119\n",
      "Epoch: [95/200], Batch: 89, Discriminator loss: 0.6869792342185974, Generator loss: 0.645561695098877\n",
      "Epoch: [96/200], Batch: 29, Discriminator loss: 0.6821597218513489, Generator loss: 0.7683706879615784\n",
      "Epoch: [96/200], Batch: 59, Discriminator loss: 0.6854251027107239, Generator loss: 0.6555728912353516\n",
      "Epoch: [96/200], Batch: 89, Discriminator loss: 0.6861722469329834, Generator loss: 0.736393392086029\n",
      "Epoch: [97/200], Batch: 29, Discriminator loss: 0.6916510462760925, Generator loss: 0.6670576333999634\n",
      "Epoch: [97/200], Batch: 59, Discriminator loss: 0.6949132680892944, Generator loss: 0.7145420908927917\n",
      "Epoch: [97/200], Batch: 89, Discriminator loss: 0.6845018863677979, Generator loss: 0.707797110080719\n",
      "Epoch: [98/200], Batch: 29, Discriminator loss: 0.6884524822235107, Generator loss: 0.6926222443580627\n",
      "Epoch: [98/200], Batch: 59, Discriminator loss: 0.6913723945617676, Generator loss: 0.674604058265686\n",
      "Epoch: [98/200], Batch: 89, Discriminator loss: 0.6988393664360046, Generator loss: 0.6383793950080872\n",
      "Epoch: [99/200], Batch: 29, Discriminator loss: 0.7033803462982178, Generator loss: 0.6893279552459717\n",
      "Epoch: [99/200], Batch: 59, Discriminator loss: 0.7000006437301636, Generator loss: 0.6579629778862\n",
      "Epoch: [99/200], Batch: 89, Discriminator loss: 0.6904813051223755, Generator loss: 0.6861968040466309\n",
      "Epoch: [100/200], Batch: 29, Discriminator loss: 0.7025716304779053, Generator loss: 0.7685207724571228\n",
      "Epoch: [100/200], Batch: 59, Discriminator loss: 0.7068668603897095, Generator loss: 0.5646506547927856\n",
      "Epoch: [100/200], Batch: 89, Discriminator loss: 0.6955884099006653, Generator loss: 0.7165802121162415\n",
      "Epoch: [101/200], Batch: 29, Discriminator loss: 0.6651027202606201, Generator loss: 0.6175714135169983\n",
      "Epoch: [101/200], Batch: 59, Discriminator loss: 0.7057362794876099, Generator loss: 0.7648899555206299\n",
      "Epoch: [101/200], Batch: 89, Discriminator loss: 0.6804932951927185, Generator loss: 0.655805230140686\n",
      "Epoch: [102/200], Batch: 29, Discriminator loss: 0.6689729690551758, Generator loss: 0.6750392317771912\n",
      "Epoch: [102/200], Batch: 59, Discriminator loss: 0.6754639148712158, Generator loss: 0.6383242607116699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [102/200], Batch: 89, Discriminator loss: 0.6898358464241028, Generator loss: 0.7908338904380798\n",
      "Epoch: [103/200], Batch: 29, Discriminator loss: 0.6842859983444214, Generator loss: 0.6815932393074036\n",
      "Epoch: [103/200], Batch: 59, Discriminator loss: 0.6854018568992615, Generator loss: 0.7483932971954346\n",
      "Epoch: [103/200], Batch: 89, Discriminator loss: 0.6781660914421082, Generator loss: 0.7099917531013489\n",
      "Epoch: [104/200], Batch: 29, Discriminator loss: 0.7024356126785278, Generator loss: 0.6978514194488525\n",
      "Epoch: [104/200], Batch: 59, Discriminator loss: 0.6925504803657532, Generator loss: 0.738875150680542\n",
      "Epoch: [104/200], Batch: 89, Discriminator loss: 0.6957381963729858, Generator loss: 0.7784092426300049\n",
      "Epoch: [105/200], Batch: 29, Discriminator loss: 0.7143343687057495, Generator loss: 0.6690592765808105\n",
      "Epoch: [105/200], Batch: 59, Discriminator loss: 0.7004361152648926, Generator loss: 0.6875396370887756\n",
      "Epoch: [105/200], Batch: 89, Discriminator loss: 0.6868148446083069, Generator loss: 0.6549955606460571\n",
      "Epoch: [106/200], Batch: 29, Discriminator loss: 0.6885107159614563, Generator loss: 0.6066010594367981\n",
      "Epoch: [106/200], Batch: 59, Discriminator loss: 0.6923510432243347, Generator loss: 0.7282134294509888\n",
      "Epoch: [106/200], Batch: 89, Discriminator loss: 0.6885411143302917, Generator loss: 0.777087926864624\n",
      "Epoch: [107/200], Batch: 29, Discriminator loss: 0.6913168430328369, Generator loss: 0.6345146894454956\n",
      "Epoch: [107/200], Batch: 59, Discriminator loss: 0.658277153968811, Generator loss: 0.672490656375885\n",
      "Epoch: [107/200], Batch: 89, Discriminator loss: 0.6923308968544006, Generator loss: 0.6717935800552368\n",
      "Epoch: [108/200], Batch: 29, Discriminator loss: 0.6938998699188232, Generator loss: 0.6651630401611328\n",
      "Epoch: [108/200], Batch: 59, Discriminator loss: 0.6801866292953491, Generator loss: 0.7282424569129944\n",
      "Epoch: [108/200], Batch: 89, Discriminator loss: 0.6948609352111816, Generator loss: 0.7121708393096924\n",
      "Epoch: [109/200], Batch: 29, Discriminator loss: 0.6895776987075806, Generator loss: 0.7158166766166687\n",
      "Epoch: [109/200], Batch: 59, Discriminator loss: 0.692348062992096, Generator loss: 0.6994178295135498\n",
      "Epoch: [109/200], Batch: 89, Discriminator loss: 0.6945943236351013, Generator loss: 0.6811978816986084\n",
      "Epoch: [110/200], Batch: 29, Discriminator loss: 0.6905531883239746, Generator loss: 0.6964681148529053\n",
      "Epoch: [110/200], Batch: 59, Discriminator loss: 0.6993253827095032, Generator loss: 0.7291041016578674\n",
      "Epoch: [110/200], Batch: 89, Discriminator loss: 0.7004125118255615, Generator loss: 0.6498153209686279\n",
      "Epoch: [111/200], Batch: 29, Discriminator loss: 0.6978063583374023, Generator loss: 0.7015317678451538\n",
      "Epoch: [111/200], Batch: 59, Discriminator loss: 0.7426369190216064, Generator loss: 0.7543947696685791\n",
      "Epoch: [111/200], Batch: 89, Discriminator loss: 0.6878470182418823, Generator loss: 0.7363941669464111\n",
      "Epoch: [112/200], Batch: 29, Discriminator loss: 0.6887387037277222, Generator loss: 0.679259181022644\n",
      "Epoch: [112/200], Batch: 59, Discriminator loss: 0.6967447400093079, Generator loss: 0.7734015583992004\n",
      "Epoch: [112/200], Batch: 89, Discriminator loss: 0.6873490214347839, Generator loss: 0.7297109961509705\n",
      "Epoch: [113/200], Batch: 29, Discriminator loss: 0.6700237989425659, Generator loss: 0.6210794448852539\n",
      "Epoch: [113/200], Batch: 59, Discriminator loss: 0.6820242404937744, Generator loss: 0.7181922793388367\n",
      "Epoch: [113/200], Batch: 89, Discriminator loss: 0.6928750276565552, Generator loss: 0.6773032546043396\n",
      "Epoch: [114/200], Batch: 29, Discriminator loss: 0.7085639238357544, Generator loss: 0.7501375079154968\n",
      "Epoch: [114/200], Batch: 59, Discriminator loss: 0.6877154111862183, Generator loss: 0.7259239554405212\n",
      "Epoch: [114/200], Batch: 89, Discriminator loss: 0.6867574453353882, Generator loss: 0.7322666645050049\n",
      "Epoch: [115/200], Batch: 29, Discriminator loss: 0.6906038522720337, Generator loss: 0.6964122653007507\n",
      "Epoch: [115/200], Batch: 59, Discriminator loss: 0.6727045178413391, Generator loss: 0.6836928129196167\n",
      "Epoch: [115/200], Batch: 89, Discriminator loss: 0.6716786623001099, Generator loss: 0.7018194198608398\n",
      "Epoch: [116/200], Batch: 29, Discriminator loss: 0.7499756813049316, Generator loss: 0.6983888149261475\n",
      "Epoch: [116/200], Batch: 59, Discriminator loss: 0.6698306798934937, Generator loss: 0.762937068939209\n",
      "Epoch: [116/200], Batch: 89, Discriminator loss: 0.7030222415924072, Generator loss: 0.6762943863868713\n",
      "Epoch: [117/200], Batch: 29, Discriminator loss: 0.6885592937469482, Generator loss: 0.718620777130127\n",
      "Epoch: [117/200], Batch: 59, Discriminator loss: 0.7105971574783325, Generator loss: 0.7276774048805237\n",
      "Epoch: [117/200], Batch: 89, Discriminator loss: 0.7078494429588318, Generator loss: 0.7266477346420288\n",
      "Epoch: [118/200], Batch: 29, Discriminator loss: 0.7214481830596924, Generator loss: 0.805229127407074\n",
      "Epoch: [118/200], Batch: 59, Discriminator loss: 0.7050368189811707, Generator loss: 0.6798022985458374\n",
      "Epoch: [118/200], Batch: 89, Discriminator loss: 0.683512806892395, Generator loss: 0.7002838850021362\n",
      "Epoch: [119/200], Batch: 29, Discriminator loss: 0.6874880194664001, Generator loss: 0.7336335778236389\n",
      "Epoch: [119/200], Batch: 59, Discriminator loss: 0.687347412109375, Generator loss: 0.7040842771530151\n",
      "Epoch: [119/200], Batch: 89, Discriminator loss: 0.6646471619606018, Generator loss: 0.7045366764068604\n",
      "Epoch: [120/200], Batch: 29, Discriminator loss: 0.689485490322113, Generator loss: 0.694378674030304\n",
      "Epoch: [120/200], Batch: 59, Discriminator loss: 0.7086206674575806, Generator loss: 0.6869431734085083\n",
      "Epoch: [120/200], Batch: 89, Discriminator loss: 0.6855878829956055, Generator loss: 0.7210372686386108\n",
      "Epoch: [121/200], Batch: 29, Discriminator loss: 0.6943979263305664, Generator loss: 0.7768426537513733\n",
      "Epoch: [121/200], Batch: 59, Discriminator loss: 0.6970661878585815, Generator loss: 0.7343748807907104\n",
      "Epoch: [121/200], Batch: 89, Discriminator loss: 0.6826614737510681, Generator loss: 0.6905243992805481\n",
      "Epoch: [122/200], Batch: 29, Discriminator loss: 0.7058596611022949, Generator loss: 0.7239851355552673\n",
      "Epoch: [122/200], Batch: 59, Discriminator loss: 0.6900359392166138, Generator loss: 0.7445478439331055\n",
      "Epoch: [122/200], Batch: 89, Discriminator loss: 0.7310054302215576, Generator loss: 0.7205337285995483\n",
      "Epoch: [123/200], Batch: 29, Discriminator loss: 0.705062747001648, Generator loss: 0.6902631521224976\n",
      "Epoch: [123/200], Batch: 59, Discriminator loss: 0.6897571086883545, Generator loss: 0.7206162214279175\n",
      "Epoch: [123/200], Batch: 89, Discriminator loss: 0.6857895255088806, Generator loss: 0.6686703562736511\n",
      "Epoch: [124/200], Batch: 29, Discriminator loss: 0.6956163644790649, Generator loss: 0.6675024032592773\n",
      "Epoch: [124/200], Batch: 59, Discriminator loss: 0.6964831948280334, Generator loss: 0.7119296789169312\n",
      "Epoch: [124/200], Batch: 89, Discriminator loss: 0.6939712166786194, Generator loss: 0.6890819668769836\n",
      "Epoch: [125/200], Batch: 29, Discriminator loss: 0.6784760355949402, Generator loss: 0.6868239641189575\n",
      "Epoch: [125/200], Batch: 59, Discriminator loss: 0.6843112707138062, Generator loss: 0.6957524418830872\n",
      "Epoch: [125/200], Batch: 89, Discriminator loss: 0.6868619322776794, Generator loss: 0.7386581897735596\n",
      "Epoch: [126/200], Batch: 29, Discriminator loss: 0.6876736283302307, Generator loss: 0.7040274739265442\n",
      "Epoch: [126/200], Batch: 59, Discriminator loss: 0.6923786401748657, Generator loss: 0.7017248868942261\n",
      "Epoch: [126/200], Batch: 89, Discriminator loss: 0.6763825416564941, Generator loss: 0.6476218700408936\n",
      "Epoch: [127/200], Batch: 29, Discriminator loss: 0.6966497898101807, Generator loss: 0.7294192314147949\n",
      "Epoch: [127/200], Batch: 59, Discriminator loss: 0.6858892440795898, Generator loss: 0.7416749000549316\n",
      "Epoch: [127/200], Batch: 89, Discriminator loss: 0.703460693359375, Generator loss: 0.6820439696311951\n",
      "Epoch: [128/200], Batch: 29, Discriminator loss: 0.694942831993103, Generator loss: 0.6502740383148193\n",
      "Epoch: [128/200], Batch: 59, Discriminator loss: 0.6974894404411316, Generator loss: 0.6882278919219971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [128/200], Batch: 89, Discriminator loss: 0.6875128149986267, Generator loss: 0.6570866107940674\n",
      "Epoch: [129/200], Batch: 29, Discriminator loss: 0.6950758695602417, Generator loss: 0.6900593042373657\n",
      "Epoch: [129/200], Batch: 59, Discriminator loss: 0.7135376930236816, Generator loss: 0.6473790407180786\n",
      "Epoch: [129/200], Batch: 89, Discriminator loss: 0.7106525301933289, Generator loss: 0.6694252490997314\n",
      "Epoch: [130/200], Batch: 29, Discriminator loss: 0.6879503130912781, Generator loss: 0.6857303977012634\n",
      "Epoch: [130/200], Batch: 59, Discriminator loss: 0.6994649171829224, Generator loss: 0.6817246675491333\n",
      "Epoch: [130/200], Batch: 89, Discriminator loss: 0.6923009753227234, Generator loss: 0.6920852065086365\n",
      "Epoch: [131/200], Batch: 29, Discriminator loss: 0.6804088950157166, Generator loss: 0.8522633910179138\n",
      "Epoch: [131/200], Batch: 59, Discriminator loss: 0.686031699180603, Generator loss: 0.7051724195480347\n",
      "Epoch: [131/200], Batch: 89, Discriminator loss: 0.6950646638870239, Generator loss: 0.7216882705688477\n",
      "Epoch: [132/200], Batch: 29, Discriminator loss: 0.7009422183036804, Generator loss: 0.821053683757782\n",
      "Epoch: [132/200], Batch: 59, Discriminator loss: 0.6952984929084778, Generator loss: 0.7041487097740173\n",
      "Epoch: [132/200], Batch: 89, Discriminator loss: 0.6946457028388977, Generator loss: 0.6971449851989746\n",
      "Epoch: [133/200], Batch: 29, Discriminator loss: 0.6965693235397339, Generator loss: 0.7204951047897339\n",
      "Epoch: [133/200], Batch: 59, Discriminator loss: 0.6964547634124756, Generator loss: 0.6903496384620667\n",
      "Epoch: [133/200], Batch: 89, Discriminator loss: 0.6763116121292114, Generator loss: 0.749264657497406\n",
      "Epoch: [134/200], Batch: 29, Discriminator loss: 0.6754006743431091, Generator loss: 0.6929853558540344\n",
      "Epoch: [134/200], Batch: 59, Discriminator loss: 0.7406855821609497, Generator loss: 0.7424222230911255\n",
      "Epoch: [134/200], Batch: 89, Discriminator loss: 0.6866531372070312, Generator loss: 0.679651141166687\n",
      "Epoch: [135/200], Batch: 29, Discriminator loss: 0.7028616666793823, Generator loss: 0.7547481060028076\n",
      "Epoch: [135/200], Batch: 59, Discriminator loss: 0.6945333480834961, Generator loss: 0.6972516179084778\n",
      "Epoch: [135/200], Batch: 89, Discriminator loss: 0.7136806845664978, Generator loss: 0.6936320662498474\n",
      "Epoch: [136/200], Batch: 29, Discriminator loss: 0.6894515752792358, Generator loss: 0.740827202796936\n",
      "Epoch: [136/200], Batch: 59, Discriminator loss: 0.7120346426963806, Generator loss: 0.7483501434326172\n",
      "Epoch: [136/200], Batch: 89, Discriminator loss: 0.699463963508606, Generator loss: 0.7561852931976318\n",
      "Epoch: [137/200], Batch: 29, Discriminator loss: 0.7020283937454224, Generator loss: 0.6514853239059448\n",
      "Epoch: [137/200], Batch: 59, Discriminator loss: 0.6886883974075317, Generator loss: 0.7344493269920349\n",
      "Epoch: [137/200], Batch: 89, Discriminator loss: 0.7038757801055908, Generator loss: 0.711390495300293\n",
      "Epoch: [138/200], Batch: 29, Discriminator loss: 0.6772698760032654, Generator loss: 0.7365646362304688\n",
      "Epoch: [138/200], Batch: 59, Discriminator loss: 0.664353609085083, Generator loss: 0.6887131333351135\n",
      "Epoch: [138/200], Batch: 89, Discriminator loss: 0.6725114583969116, Generator loss: 0.7612155675888062\n",
      "Epoch: [139/200], Batch: 29, Discriminator loss: 0.6648620963096619, Generator loss: 0.6941758990287781\n",
      "Epoch: [139/200], Batch: 59, Discriminator loss: 0.6671321392059326, Generator loss: 0.7987350225448608\n",
      "Epoch: [139/200], Batch: 89, Discriminator loss: 0.7076130509376526, Generator loss: 0.753545880317688\n",
      "Epoch: [140/200], Batch: 29, Discriminator loss: 0.693569004535675, Generator loss: 0.7380465269088745\n",
      "Epoch: [140/200], Batch: 59, Discriminator loss: 0.6890762448310852, Generator loss: 0.6864956021308899\n",
      "Epoch: [140/200], Batch: 89, Discriminator loss: 0.7095546722412109, Generator loss: 0.725607693195343\n",
      "Epoch: [141/200], Batch: 29, Discriminator loss: 0.6858625411987305, Generator loss: 0.7287626266479492\n",
      "Epoch: [141/200], Batch: 59, Discriminator loss: 0.687401294708252, Generator loss: 0.6732529997825623\n",
      "Epoch: [141/200], Batch: 89, Discriminator loss: 0.6857554912567139, Generator loss: 0.7035439610481262\n",
      "Epoch: [142/200], Batch: 29, Discriminator loss: 0.6926229000091553, Generator loss: 0.6816529035568237\n",
      "Epoch: [142/200], Batch: 59, Discriminator loss: 0.7130925059318542, Generator loss: 0.7133422493934631\n",
      "Epoch: [142/200], Batch: 89, Discriminator loss: 0.6883993148803711, Generator loss: 0.6923553943634033\n",
      "Epoch: [143/200], Batch: 29, Discriminator loss: 0.6895621418952942, Generator loss: 0.6955642700195312\n",
      "Epoch: [143/200], Batch: 59, Discriminator loss: 0.7006722688674927, Generator loss: 0.7372636795043945\n",
      "Epoch: [143/200], Batch: 89, Discriminator loss: 0.7075693607330322, Generator loss: 0.6018882989883423\n",
      "Epoch: [144/200], Batch: 29, Discriminator loss: 0.6749770045280457, Generator loss: 0.7316864728927612\n",
      "Epoch: [144/200], Batch: 59, Discriminator loss: 0.6919394731521606, Generator loss: 0.6490015387535095\n",
      "Epoch: [144/200], Batch: 89, Discriminator loss: 0.695868194103241, Generator loss: 0.7334258556365967\n",
      "Epoch: [145/200], Batch: 29, Discriminator loss: 0.6881812810897827, Generator loss: 0.6985981464385986\n",
      "Epoch: [145/200], Batch: 59, Discriminator loss: 0.707943320274353, Generator loss: 0.6897472143173218\n",
      "Epoch: [145/200], Batch: 89, Discriminator loss: 0.6765397787094116, Generator loss: 0.7978761196136475\n",
      "Epoch: [146/200], Batch: 29, Discriminator loss: 0.6582290530204773, Generator loss: 0.6836543083190918\n",
      "Epoch: [146/200], Batch: 59, Discriminator loss: 0.6819923520088196, Generator loss: 0.7508177757263184\n",
      "Epoch: [146/200], Batch: 89, Discriminator loss: 0.6884042620658875, Generator loss: 0.7131444215774536\n",
      "Epoch: [147/200], Batch: 29, Discriminator loss: 0.6940286159515381, Generator loss: 0.7782424688339233\n",
      "Epoch: [147/200], Batch: 59, Discriminator loss: 0.6807050704956055, Generator loss: 0.7041306495666504\n",
      "Epoch: [147/200], Batch: 89, Discriminator loss: 0.73387610912323, Generator loss: 0.7715499401092529\n",
      "Epoch: [148/200], Batch: 29, Discriminator loss: 0.6764754056930542, Generator loss: 0.7783486843109131\n",
      "Epoch: [148/200], Batch: 59, Discriminator loss: 0.6700655221939087, Generator loss: 0.7496857047080994\n",
      "Epoch: [148/200], Batch: 89, Discriminator loss: 0.6124765872955322, Generator loss: 0.8083835244178772\n",
      "Epoch: [149/200], Batch: 29, Discriminator loss: 0.8551031351089478, Generator loss: 0.7184216976165771\n",
      "Epoch: [149/200], Batch: 59, Discriminator loss: 0.689623236656189, Generator loss: 0.7152153849601746\n",
      "Epoch: [149/200], Batch: 89, Discriminator loss: 0.7092100381851196, Generator loss: 0.7080140113830566\n",
      "Epoch: [150/200], Batch: 29, Discriminator loss: 0.7022498250007629, Generator loss: 0.7007980942726135\n",
      "Epoch: [150/200], Batch: 59, Discriminator loss: 0.687456488609314, Generator loss: 0.6987777352333069\n",
      "Epoch: [150/200], Batch: 89, Discriminator loss: 0.7039514183998108, Generator loss: 0.7082450985908508\n",
      "Epoch: [151/200], Batch: 29, Discriminator loss: 0.6970486640930176, Generator loss: 0.7005295157432556\n",
      "Epoch: [151/200], Batch: 59, Discriminator loss: 0.6943750381469727, Generator loss: 0.6819007992744446\n",
      "Epoch: [151/200], Batch: 89, Discriminator loss: 0.6878621578216553, Generator loss: 0.7121186256408691\n",
      "Epoch: [152/200], Batch: 29, Discriminator loss: 0.6959995031356812, Generator loss: 0.6956888437271118\n",
      "Epoch: [152/200], Batch: 59, Discriminator loss: 0.6895747184753418, Generator loss: 0.7164090871810913\n",
      "Epoch: [152/200], Batch: 89, Discriminator loss: 0.6985363960266113, Generator loss: 0.7087050676345825\n",
      "Epoch: [153/200], Batch: 29, Discriminator loss: 0.7093186378479004, Generator loss: 0.6949345469474792\n",
      "Epoch: [153/200], Batch: 59, Discriminator loss: 0.7059578895568848, Generator loss: 0.7100875377655029\n",
      "Epoch: [153/200], Batch: 89, Discriminator loss: 0.6916665434837341, Generator loss: 0.692872166633606\n",
      "Epoch: [154/200], Batch: 29, Discriminator loss: 0.6911053657531738, Generator loss: 0.6781234741210938\n",
      "Epoch: [154/200], Batch: 59, Discriminator loss: 0.6840078830718994, Generator loss: 0.6574862003326416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [154/200], Batch: 89, Discriminator loss: 0.6901882290840149, Generator loss: 0.7227988243103027\n",
      "Epoch: [155/200], Batch: 29, Discriminator loss: 0.6872827410697937, Generator loss: 0.6416897773742676\n",
      "Epoch: [155/200], Batch: 59, Discriminator loss: 0.6983262300491333, Generator loss: 0.6684478521347046\n",
      "Epoch: [155/200], Batch: 89, Discriminator loss: 0.6943413019180298, Generator loss: 0.6520370841026306\n",
      "Epoch: [156/200], Batch: 29, Discriminator loss: 0.7297645211219788, Generator loss: 0.6454012393951416\n",
      "Epoch: [156/200], Batch: 59, Discriminator loss: 0.7014036178588867, Generator loss: 0.6911764144897461\n",
      "Epoch: [156/200], Batch: 89, Discriminator loss: 0.6796226501464844, Generator loss: 0.6937381029129028\n",
      "Epoch: [157/200], Batch: 29, Discriminator loss: 0.6854836344718933, Generator loss: 0.692249059677124\n",
      "Epoch: [157/200], Batch: 59, Discriminator loss: 0.6948782205581665, Generator loss: 0.6866337656974792\n",
      "Epoch: [157/200], Batch: 89, Discriminator loss: 0.694705605506897, Generator loss: 0.6884868144989014\n",
      "Epoch: [158/200], Batch: 29, Discriminator loss: 0.6938040852546692, Generator loss: 0.7083972692489624\n",
      "Epoch: [158/200], Batch: 59, Discriminator loss: 0.685835063457489, Generator loss: 0.6996245980262756\n",
      "Epoch: [158/200], Batch: 89, Discriminator loss: 0.7069134712219238, Generator loss: 0.7141479849815369\n",
      "Epoch: [159/200], Batch: 29, Discriminator loss: 0.7279691696166992, Generator loss: 0.7682675123214722\n",
      "Epoch: [159/200], Batch: 59, Discriminator loss: 0.6755503416061401, Generator loss: 0.6887602210044861\n",
      "Epoch: [159/200], Batch: 89, Discriminator loss: 0.6740946173667908, Generator loss: 0.6317474246025085\n",
      "Epoch: [160/200], Batch: 29, Discriminator loss: 0.6546050906181335, Generator loss: 0.7860397100448608\n",
      "Epoch: [160/200], Batch: 59, Discriminator loss: 0.7245039343833923, Generator loss: 0.7963184118270874\n",
      "Epoch: [160/200], Batch: 89, Discriminator loss: 0.6658793687820435, Generator loss: 0.9233303666114807\n",
      "Epoch: [161/200], Batch: 29, Discriminator loss: 0.703040361404419, Generator loss: 0.699308454990387\n",
      "Epoch: [161/200], Batch: 59, Discriminator loss: 0.640119194984436, Generator loss: 0.7936763167381287\n",
      "Epoch: [161/200], Batch: 89, Discriminator loss: 0.653141438961029, Generator loss: 0.7687864303588867\n",
      "Epoch: [162/200], Batch: 29, Discriminator loss: 0.6852725148200989, Generator loss: 0.76766037940979\n",
      "Epoch: [162/200], Batch: 59, Discriminator loss: 0.6836816668510437, Generator loss: 0.6999796628952026\n",
      "Epoch: [162/200], Batch: 89, Discriminator loss: 0.7051244378089905, Generator loss: 0.7625194191932678\n",
      "Epoch: [163/200], Batch: 29, Discriminator loss: 0.6924086809158325, Generator loss: 0.6919267177581787\n",
      "Epoch: [163/200], Batch: 59, Discriminator loss: 0.6977068185806274, Generator loss: 0.7058238983154297\n",
      "Epoch: [163/200], Batch: 89, Discriminator loss: 0.6856644749641418, Generator loss: 0.6728834509849548\n",
      "Epoch: [164/200], Batch: 29, Discriminator loss: 0.6494352221488953, Generator loss: 0.7091359496116638\n",
      "Epoch: [164/200], Batch: 59, Discriminator loss: 0.6715624928474426, Generator loss: 0.9062814116477966\n",
      "Epoch: [164/200], Batch: 89, Discriminator loss: 0.7133898735046387, Generator loss: 0.7133091688156128\n",
      "Epoch: [165/200], Batch: 29, Discriminator loss: 0.7117907404899597, Generator loss: 0.6677020788192749\n",
      "Epoch: [165/200], Batch: 59, Discriminator loss: 0.6926082372665405, Generator loss: 0.7497655749320984\n",
      "Epoch: [165/200], Batch: 89, Discriminator loss: 0.7001112699508667, Generator loss: 0.7212029099464417\n",
      "Epoch: [166/200], Batch: 29, Discriminator loss: 0.677972674369812, Generator loss: 0.6672176718711853\n",
      "Epoch: [166/200], Batch: 59, Discriminator loss: 0.6606041193008423, Generator loss: 0.7330073118209839\n",
      "Epoch: [166/200], Batch: 89, Discriminator loss: 0.6797665953636169, Generator loss: 0.7166391611099243\n",
      "Epoch: [167/200], Batch: 29, Discriminator loss: 0.649297833442688, Generator loss: 0.8096249103546143\n",
      "Epoch: [167/200], Batch: 59, Discriminator loss: 0.6790125966072083, Generator loss: 0.6814948916435242\n",
      "Epoch: [167/200], Batch: 89, Discriminator loss: 0.7237913012504578, Generator loss: 0.7164021134376526\n",
      "Epoch: [168/200], Batch: 29, Discriminator loss: 0.6720690131187439, Generator loss: 0.7590384483337402\n",
      "Epoch: [168/200], Batch: 59, Discriminator loss: 0.6916012167930603, Generator loss: 0.7047298550605774\n",
      "Epoch: [168/200], Batch: 89, Discriminator loss: 0.7184908390045166, Generator loss: 0.7877527475357056\n",
      "Epoch: [169/200], Batch: 29, Discriminator loss: 0.6781893968582153, Generator loss: 0.6986837387084961\n",
      "Epoch: [169/200], Batch: 59, Discriminator loss: 0.6825112700462341, Generator loss: 0.7445592880249023\n",
      "Epoch: [169/200], Batch: 89, Discriminator loss: 0.7078391313552856, Generator loss: 0.7146310806274414\n",
      "Epoch: [170/200], Batch: 29, Discriminator loss: 0.6723231077194214, Generator loss: 0.6832055449485779\n",
      "Epoch: [170/200], Batch: 59, Discriminator loss: 0.6928171515464783, Generator loss: 0.8213137984275818\n",
      "Epoch: [170/200], Batch: 89, Discriminator loss: 0.6886039972305298, Generator loss: 0.8123531937599182\n",
      "Epoch: [171/200], Batch: 29, Discriminator loss: 0.7190118432044983, Generator loss: 0.7381494641304016\n",
      "Epoch: [171/200], Batch: 59, Discriminator loss: 0.6725643873214722, Generator loss: 0.7652453184127808\n",
      "Epoch: [171/200], Batch: 89, Discriminator loss: 0.6952357292175293, Generator loss: 0.7097893357276917\n",
      "Epoch: [172/200], Batch: 29, Discriminator loss: 0.6736895442008972, Generator loss: 0.7220816016197205\n",
      "Epoch: [172/200], Batch: 59, Discriminator loss: 0.6853460669517517, Generator loss: 0.7762235403060913\n",
      "Epoch: [172/200], Batch: 89, Discriminator loss: 0.6945890188217163, Generator loss: 0.8306676149368286\n",
      "Epoch: [173/200], Batch: 29, Discriminator loss: 0.6946529746055603, Generator loss: 0.6917358636856079\n",
      "Epoch: [173/200], Batch: 59, Discriminator loss: 0.66855388879776, Generator loss: 0.6737495064735413\n",
      "Epoch: [173/200], Batch: 89, Discriminator loss: 0.7111679315567017, Generator loss: 0.8816240429878235\n",
      "Epoch: [174/200], Batch: 29, Discriminator loss: 0.6968271732330322, Generator loss: 0.7420592904090881\n",
      "Epoch: [174/200], Batch: 59, Discriminator loss: 0.6804640889167786, Generator loss: 0.7099910378456116\n",
      "Epoch: [174/200], Batch: 89, Discriminator loss: 0.6821925640106201, Generator loss: 0.6455880403518677\n",
      "Epoch: [175/200], Batch: 29, Discriminator loss: 0.7219828367233276, Generator loss: 0.6266140341758728\n",
      "Epoch: [175/200], Batch: 59, Discriminator loss: 0.6926516890525818, Generator loss: 0.7209764719009399\n",
      "Epoch: [175/200], Batch: 89, Discriminator loss: 0.6759532690048218, Generator loss: 0.7830780148506165\n",
      "Epoch: [176/200], Batch: 29, Discriminator loss: 0.6881575584411621, Generator loss: 0.7149988412857056\n",
      "Epoch: [176/200], Batch: 59, Discriminator loss: 0.6933566927909851, Generator loss: 0.6903883814811707\n",
      "Epoch: [176/200], Batch: 89, Discriminator loss: 0.7123298645019531, Generator loss: 0.7201061844825745\n",
      "Epoch: [177/200], Batch: 29, Discriminator loss: 0.696462869644165, Generator loss: 0.7177163362503052\n",
      "Epoch: [177/200], Batch: 59, Discriminator loss: 0.6958111524581909, Generator loss: 0.7149932384490967\n",
      "Epoch: [177/200], Batch: 89, Discriminator loss: 0.6820312738418579, Generator loss: 0.7248523831367493\n",
      "Epoch: [178/200], Batch: 29, Discriminator loss: 0.7317953705787659, Generator loss: 0.716066837310791\n",
      "Epoch: [178/200], Batch: 59, Discriminator loss: 0.6967557668685913, Generator loss: 0.7043423652648926\n",
      "Epoch: [178/200], Batch: 89, Discriminator loss: 0.6589205861091614, Generator loss: 0.6079108715057373\n",
      "Epoch: [179/200], Batch: 29, Discriminator loss: 0.6835857629776001, Generator loss: 0.7927752137184143\n",
      "Epoch: [179/200], Batch: 59, Discriminator loss: 0.681117594242096, Generator loss: 0.719264030456543\n",
      "Epoch: [179/200], Batch: 89, Discriminator loss: 0.6970610618591309, Generator loss: 0.6737401485443115\n",
      "Epoch: [180/200], Batch: 29, Discriminator loss: 0.6832879781723022, Generator loss: 0.6877074241638184\n",
      "Epoch: [180/200], Batch: 59, Discriminator loss: 0.713026225566864, Generator loss: 0.7829737663269043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [180/200], Batch: 89, Discriminator loss: 0.6766225099563599, Generator loss: 0.7453994154930115\n",
      "Epoch: [181/200], Batch: 29, Discriminator loss: 0.6639509201049805, Generator loss: 1.0208442211151123\n",
      "Epoch: [181/200], Batch: 59, Discriminator loss: 0.6827775239944458, Generator loss: 0.6780500411987305\n",
      "Epoch: [181/200], Batch: 89, Discriminator loss: 0.7066287398338318, Generator loss: 0.6692141890525818\n",
      "Epoch: [182/200], Batch: 29, Discriminator loss: 0.6998308300971985, Generator loss: 0.7134473919868469\n",
      "Epoch: [182/200], Batch: 59, Discriminator loss: 0.6924208402633667, Generator loss: 0.7689681053161621\n",
      "Epoch: [182/200], Batch: 89, Discriminator loss: 0.6947664618492126, Generator loss: 0.7175596356391907\n",
      "Epoch: [183/200], Batch: 29, Discriminator loss: 0.68523770570755, Generator loss: 0.6790178418159485\n",
      "Epoch: [183/200], Batch: 59, Discriminator loss: 0.719928503036499, Generator loss: 0.7998639345169067\n",
      "Epoch: [183/200], Batch: 89, Discriminator loss: 0.6974765062332153, Generator loss: 0.7367669343948364\n",
      "Epoch: [184/200], Batch: 29, Discriminator loss: 0.6858643293380737, Generator loss: 0.76051926612854\n",
      "Epoch: [184/200], Batch: 59, Discriminator loss: 0.679375171661377, Generator loss: 0.6927038431167603\n",
      "Epoch: [184/200], Batch: 89, Discriminator loss: 0.7064975500106812, Generator loss: 0.748546302318573\n",
      "Epoch: [185/200], Batch: 29, Discriminator loss: 0.7198588252067566, Generator loss: 0.6016231775283813\n",
      "Epoch: [185/200], Batch: 59, Discriminator loss: 0.7180101275444031, Generator loss: 0.6871093511581421\n",
      "Epoch: [185/200], Batch: 89, Discriminator loss: 0.6679092049598694, Generator loss: 0.6793923377990723\n",
      "Epoch: [186/200], Batch: 29, Discriminator loss: 0.7042337656021118, Generator loss: 0.7676001787185669\n",
      "Epoch: [186/200], Batch: 59, Discriminator loss: 0.6821389198303223, Generator loss: 0.7041557431221008\n",
      "Epoch: [186/200], Batch: 89, Discriminator loss: 0.6834414601325989, Generator loss: 0.7589687705039978\n",
      "Epoch: [187/200], Batch: 29, Discriminator loss: 0.6694251298904419, Generator loss: 0.853024423122406\n",
      "Epoch: [187/200], Batch: 59, Discriminator loss: 0.6932309865951538, Generator loss: 0.6674633026123047\n",
      "Epoch: [187/200], Batch: 89, Discriminator loss: 0.6671496033668518, Generator loss: 0.6559152603149414\n",
      "Epoch: [188/200], Batch: 29, Discriminator loss: 0.7142989635467529, Generator loss: 0.7180874347686768\n",
      "Epoch: [188/200], Batch: 59, Discriminator loss: 0.6784747838973999, Generator loss: 0.7056726217269897\n",
      "Epoch: [188/200], Batch: 89, Discriminator loss: 0.6810719966888428, Generator loss: 0.7341047525405884\n",
      "Epoch: [189/200], Batch: 29, Discriminator loss: 0.6981712579727173, Generator loss: 0.7510735988616943\n",
      "Epoch: [189/200], Batch: 59, Discriminator loss: 0.6880193948745728, Generator loss: 0.7258721590042114\n",
      "Epoch: [189/200], Batch: 89, Discriminator loss: 0.6956833600997925, Generator loss: 0.7331727743148804\n",
      "Epoch: [190/200], Batch: 29, Discriminator loss: 0.7102385759353638, Generator loss: 0.6872690916061401\n",
      "Epoch: [190/200], Batch: 59, Discriminator loss: 0.6756494045257568, Generator loss: 0.6880877614021301\n",
      "Epoch: [190/200], Batch: 89, Discriminator loss: 0.6893470883369446, Generator loss: 0.6687932014465332\n",
      "Epoch: [191/200], Batch: 29, Discriminator loss: 0.6994146108627319, Generator loss: 0.6657155752182007\n",
      "Epoch: [191/200], Batch: 59, Discriminator loss: 0.6987279057502747, Generator loss: 0.7183324694633484\n",
      "Epoch: [191/200], Batch: 89, Discriminator loss: 0.6801955699920654, Generator loss: 0.8738972544670105\n",
      "Epoch: [192/200], Batch: 29, Discriminator loss: 0.6958376169204712, Generator loss: 0.6828404068946838\n",
      "Epoch: [192/200], Batch: 59, Discriminator loss: 0.7075691819190979, Generator loss: 0.7562844157218933\n",
      "Epoch: [192/200], Batch: 89, Discriminator loss: 0.6919423341751099, Generator loss: 0.7713792324066162\n",
      "Epoch: [193/200], Batch: 29, Discriminator loss: 0.7026697993278503, Generator loss: 0.7133051156997681\n",
      "Epoch: [193/200], Batch: 59, Discriminator loss: 0.6734088659286499, Generator loss: 0.731476902961731\n",
      "Epoch: [193/200], Batch: 89, Discriminator loss: 0.7341660857200623, Generator loss: 0.7344551086425781\n",
      "Epoch: [194/200], Batch: 29, Discriminator loss: 0.7294625043869019, Generator loss: 0.7344871759414673\n",
      "Epoch: [194/200], Batch: 59, Discriminator loss: 0.6984521150588989, Generator loss: 0.7107963562011719\n",
      "Epoch: [194/200], Batch: 89, Discriminator loss: 0.703636884689331, Generator loss: 0.6577438116073608\n",
      "Epoch: [195/200], Batch: 29, Discriminator loss: 0.6873759031295776, Generator loss: 0.6596499681472778\n",
      "Epoch: [195/200], Batch: 59, Discriminator loss: 0.6874402165412903, Generator loss: 0.6972751617431641\n",
      "Epoch: [195/200], Batch: 89, Discriminator loss: 0.6823289394378662, Generator loss: 0.7174439430236816\n",
      "Epoch: [196/200], Batch: 29, Discriminator loss: 0.7191270589828491, Generator loss: 0.7396489977836609\n",
      "Epoch: [196/200], Batch: 59, Discriminator loss: 0.6750757694244385, Generator loss: 0.7828980088233948\n",
      "Epoch: [196/200], Batch: 89, Discriminator loss: 0.6735800504684448, Generator loss: 0.6740857362747192\n",
      "Epoch: [197/200], Batch: 29, Discriminator loss: 0.7007868885993958, Generator loss: 0.698743999004364\n",
      "Epoch: [197/200], Batch: 59, Discriminator loss: 0.6982144117355347, Generator loss: 0.8249877095222473\n",
      "Epoch: [197/200], Batch: 89, Discriminator loss: 0.7073628306388855, Generator loss: 0.7457400560379028\n",
      "Epoch: [198/200], Batch: 29, Discriminator loss: 0.6933526992797852, Generator loss: 0.6696012020111084\n",
      "Epoch: [198/200], Batch: 59, Discriminator loss: 0.6863830089569092, Generator loss: 0.7037543654441833\n",
      "Epoch: [198/200], Batch: 89, Discriminator loss: 0.6884210109710693, Generator loss: 0.7211579084396362\n",
      "Epoch: [199/200], Batch: 29, Discriminator loss: 0.7304369211196899, Generator loss: 0.7585141658782959\n",
      "Epoch: [199/200], Batch: 59, Discriminator loss: 0.6853570938110352, Generator loss: 0.6909387111663818\n",
      "Epoch: [199/200], Batch: 89, Discriminator loss: 0.6937776207923889, Generator loss: 0.6923814415931702\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "train and test GAN model on airfoils\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from dataset import AirfoilDataset\n",
    "#from gan import Discriminator, Generator\n",
    "#from utils import *\n",
    "\n",
    "\n",
    "def main():\n",
    "    # check if cuda available\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    \n",
    "    # define dataset and dataloader\n",
    "    dataset = AirfoilDataset()\n",
    "    airfoil_x = dataset.get_x()\n",
    "    airfoil_dim = airfoil_x.shape[0]\n",
    "    airfoil_dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # hyperparameters\n",
    "    latent_dim = 16 # please do not change latent dimension\n",
    "    lr_dis = 0.0005 # discriminator learning rate\n",
    "    lr_gen = 0.0005 # generator learning rate\n",
    "    BETA1 = 0.5\n",
    "    BETA2 = 0.999\n",
    "    num_epochs = 200\n",
    "    \n",
    "    # build the model\n",
    "    dis = Discriminator(input_dim=airfoil_dim).to(device)\n",
    "    gen = Generator(latent_dim=latent_dim, airfoil_dim=airfoil_dim).to(device)\n",
    "    print(\"Distrminator model:\\n\", dis)\n",
    "    print(\"Generator model:\\n\", gen)\n",
    "\n",
    "    # define your GAN loss function here\n",
    "    # you may need to define your own GAN loss function/class\n",
    "    # loss = ?\n",
    "    def dis_loss(inputs, hits):\n",
    "        return nn.BCELoss()(inputs, hits)\n",
    "    \n",
    "    def gen_loss(inputs):\n",
    "        hits = torch.ones([inputs.shape[0], 1])\n",
    "        hits = hits.to(device)\n",
    "        return nn.BCELoss()(inputs, hits)\n",
    "    \n",
    "    # define optimizer for discriminator and generator separately\n",
    "    optim_dis = Adam(dis.parameters(), lr=lr_dis, betas = (BETA1,BETA2))\n",
    "    optim_gen = Adam(gen.parameters(), lr=lr_gen, betas = (BETA1,BETA2))\n",
    "    \n",
    "    # train the GAN model\n",
    "    for epoch in range(num_epochs):\n",
    "        for n_batch, (local_batch, __) in enumerate(airfoil_dataloader):\n",
    "            y_real = local_batch.to(device)\n",
    "            \n",
    "            real_data = y_real.view(-1, 200)\n",
    "            real_out = dis(real_data)\n",
    "            real_L = torch.ones(real_data.shape[0], 1).to(device)\n",
    "            \n",
    "            \n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (y_real.shape[0], latent_dim))))\n",
    "            fakes = gen(z)\n",
    "            fakes_out = dis(fakes)\n",
    "            fake_L = torch.zeros(fakes.shape[0], 1).to(device)\n",
    "            \n",
    "            out = torch.cat((real_out, fakes_out), 0)\n",
    "            hits = torch.cat((real_L, fake_L), 0)\n",
    "            \n",
    "            optim_dis.zero_grad()\n",
    "            \n",
    "            d_loss = dis_loss(out, hits)\n",
    "            d_loss.backward()\n",
    "            optim_dis.step()\n",
    "            \n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (y_real.shape[0], latent_dim))))\n",
    "            fakes = gen(z)\n",
    "            fakes_out = dis(fakes)\n",
    "\n",
    "            g_loss = gen_loss(fakes_out)\n",
    "            optim_gen.zero_grad()\n",
    "            g_loss.backward()\n",
    "            optim_gen.step()\n",
    "            \n",
    "            # print loss while training\n",
    "            if (n_batch + 1) % 30 == 0:\n",
    "                print(\"Epoch: [{}/{}], Batch: {}, Discriminator loss: {}, Generator loss: {}\".format(\n",
    "                    epoch, num_epochs, n_batch, d_loss.item(), g_loss.item()))\n",
    "\n",
    "    # test trained GAN model\n",
    "    num_samples = 100\n",
    "    # create random noise \n",
    "    noise = torch.randn((num_samples, latent_dim)).to(device)\n",
    "    # generate airfoils\n",
    "    gen_airfoils = gen(noise)\n",
    "    if 'cuda' in device:\n",
    "        gen_airfoils = gen_airfoils.detach().cpu().numpy()\n",
    "    else:\n",
    "        gen_airfoils = gen_airfoils.detach().numpy()\n",
    "\n",
    "    # plot generated airfoils\n",
    "    plot_airfoils(airfoil_x, gen_airfoils)\n",
    "    \n",
    "    torch.save(gen,'p1_gen_model_V3.pth')\n",
    "    torch.save(dis,'p1_dis_model_V3.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "###########################################\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, airfoil_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        input_dim = airfoil_dim \n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc31 = nn.Linear(256,latent_dim)\n",
    "        self.fc32 = nn.Linear(256, latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, 256)\n",
    "        self.fc5 = nn.Linear(256,512)\n",
    "        self.fc6 = nn.Linear(512, input_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h2 = F.relu(self.fc2(h1))\n",
    "        return self.fc31(h2), self.fc32(h2)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc4(z))\n",
    "        h4 = F.relu(self.fc5(h3))\n",
    "        return torch.sigmoid(self.fc6(h4))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 200))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE model:\n",
      " VAE(\n",
      "  (fc1): Linear(in_features=200, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc31): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (fc32): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (fc4): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc6): Linear(in_features=512, out_features=200, bias=True)\n",
      ")\n",
      "Epoch: [0/35], Batch: 29, loss: -2032.644775390625\n",
      "Epoch: [0/35], Batch: 59, loss: -4223.9169921875\n",
      "Epoch: [0/35], Batch: 89, loss: -3666.10888671875\n",
      "Epoch: [1/35], Batch: 29, loss: -2874.1025390625\n",
      "Epoch: [1/35], Batch: 59, loss: -2783.8935546875\n",
      "Epoch: [1/35], Batch: 89, loss: -2684.806884765625\n",
      "Epoch: [2/35], Batch: 29, loss: -3524.30859375\n",
      "Epoch: [2/35], Batch: 59, loss: -5435.6396484375\n",
      "Epoch: [2/35], Batch: 89, loss: -6636.9052734375\n",
      "Epoch: [3/35], Batch: 29, loss: -6623.94384765625\n",
      "Epoch: [3/35], Batch: 59, loss: -10012.7587890625\n",
      "Epoch: [3/35], Batch: 89, loss: -12363.501953125\n",
      "Epoch: [4/35], Batch: 29, loss: -3447.98828125\n",
      "Epoch: [4/35], Batch: 59, loss: -9494.5283203125\n",
      "Epoch: [4/35], Batch: 89, loss: -5251.06005859375\n",
      "Epoch: [5/35], Batch: 29, loss: -2841.34228515625\n",
      "Epoch: [5/35], Batch: 59, loss: -6093.4150390625\n",
      "Epoch: [5/35], Batch: 89, loss: -8486.2275390625\n",
      "Epoch: [6/35], Batch: 29, loss: -5495.8046875\n",
      "Epoch: [6/35], Batch: 59, loss: -5837.3447265625\n",
      "Epoch: [6/35], Batch: 89, loss: -6398.005859375\n",
      "Epoch: [7/35], Batch: 29, loss: -5114.8896484375\n",
      "Epoch: [7/35], Batch: 59, loss: -6535.888671875\n",
      "Epoch: [7/35], Batch: 89, loss: -5248.2138671875\n",
      "Epoch: [8/35], Batch: 29, loss: -5480.3583984375\n",
      "Epoch: [8/35], Batch: 59, loss: -6016.18701171875\n",
      "Epoch: [8/35], Batch: 89, loss: -9082.4140625\n",
      "Epoch: [9/35], Batch: 29, loss: -8251.091796875\n",
      "Epoch: [9/35], Batch: 59, loss: -5389.98876953125\n",
      "Epoch: [9/35], Batch: 89, loss: -6700.70361328125\n",
      "Epoch: [10/35], Batch: 29, loss: -6748.52783203125\n",
      "Epoch: [10/35], Batch: 59, loss: -6595.6376953125\n",
      "Epoch: [10/35], Batch: 89, loss: -8685.548828125\n",
      "Epoch: [11/35], Batch: 29, loss: -8219.3037109375\n",
      "Epoch: [11/35], Batch: 59, loss: -9725.5498046875\n",
      "Epoch: [11/35], Batch: 89, loss: -5744.11962890625\n",
      "Epoch: [12/35], Batch: 29, loss: -8111.05078125\n",
      "Epoch: [12/35], Batch: 59, loss: -4191.85595703125\n",
      "Epoch: [12/35], Batch: 89, loss: -9268.8388671875\n",
      "Epoch: [13/35], Batch: 29, loss: -5781.5302734375\n",
      "Epoch: [13/35], Batch: 59, loss: -6243.30908203125\n",
      "Epoch: [13/35], Batch: 89, loss: -4975.9482421875\n",
      "Epoch: [14/35], Batch: 29, loss: -5721.1982421875\n",
      "Epoch: [14/35], Batch: 59, loss: -8219.17578125\n",
      "Epoch: [14/35], Batch: 89, loss: -7880.4326171875\n",
      "Epoch: [15/35], Batch: 29, loss: -6434.42919921875\n",
      "Epoch: [15/35], Batch: 59, loss: -5669.09228515625\n",
      "Epoch: [15/35], Batch: 89, loss: -6369.529296875\n",
      "Epoch: [16/35], Batch: 29, loss: -5607.611328125\n",
      "Epoch: [16/35], Batch: 59, loss: -9426.4453125\n",
      "Epoch: [16/35], Batch: 89, loss: -5373.1748046875\n",
      "Epoch: [17/35], Batch: 29, loss: -8006.10302734375\n",
      "Epoch: [17/35], Batch: 59, loss: -8571.158203125\n",
      "Epoch: [17/35], Batch: 89, loss: -8413.220703125\n",
      "Epoch: [18/35], Batch: 29, loss: -4542.65185546875\n",
      "Epoch: [18/35], Batch: 59, loss: -7761.59912109375\n",
      "Epoch: [18/35], Batch: 89, loss: -7456.9609375\n",
      "Epoch: [19/35], Batch: 29, loss: -10265.2158203125\n",
      "Epoch: [19/35], Batch: 59, loss: -7305.77099609375\n",
      "Epoch: [19/35], Batch: 89, loss: -7624.7099609375\n",
      "Epoch: [20/35], Batch: 29, loss: -3864.2041015625\n",
      "Epoch: [20/35], Batch: 59, loss: -8206.056640625\n",
      "Epoch: [20/35], Batch: 89, loss: -6224.658203125\n",
      "Epoch: [21/35], Batch: 29, loss: -6809.14501953125\n",
      "Epoch: [21/35], Batch: 59, loss: -7206.74951171875\n",
      "Epoch: [21/35], Batch: 89, loss: -7931.685546875\n",
      "Epoch: [22/35], Batch: 29, loss: -6468.748046875\n",
      "Epoch: [22/35], Batch: 59, loss: -6018.41015625\n",
      "Epoch: [22/35], Batch: 89, loss: -10857.484375\n",
      "Epoch: [23/35], Batch: 29, loss: -6247.3388671875\n",
      "Epoch: [23/35], Batch: 59, loss: -5808.947265625\n",
      "Epoch: [23/35], Batch: 89, loss: -6867.0537109375\n",
      "Epoch: [24/35], Batch: 29, loss: -9579.4873046875\n",
      "Epoch: [24/35], Batch: 59, loss: -6191.67333984375\n",
      "Epoch: [24/35], Batch: 89, loss: -5728.0556640625\n",
      "Epoch: [25/35], Batch: 29, loss: -8742.583984375\n",
      "Epoch: [25/35], Batch: 59, loss: -10104.2275390625\n",
      "Epoch: [25/35], Batch: 89, loss: -9050.9755859375\n",
      "Epoch: [26/35], Batch: 29, loss: -7407.85302734375\n",
      "Epoch: [26/35], Batch: 59, loss: -8206.4228515625\n",
      "Epoch: [26/35], Batch: 89, loss: -6485.73779296875\n",
      "Epoch: [27/35], Batch: 29, loss: -7004.61962890625\n",
      "Epoch: [27/35], Batch: 59, loss: -6993.12646484375\n",
      "Epoch: [27/35], Batch: 89, loss: -8240.0400390625\n",
      "Epoch: [28/35], Batch: 29, loss: -6795.36474609375\n",
      "Epoch: [28/35], Batch: 59, loss: -5419.220703125\n",
      "Epoch: [28/35], Batch: 89, loss: -6583.923828125\n",
      "Epoch: [29/35], Batch: 29, loss: -7363.92919921875\n",
      "Epoch: [29/35], Batch: 59, loss: -4182.1748046875\n",
      "Epoch: [29/35], Batch: 89, loss: -6897.39599609375\n",
      "Epoch: [30/35], Batch: 29, loss: -6513.52734375\n",
      "Epoch: [30/35], Batch: 59, loss: -10108.8349609375\n",
      "Epoch: [30/35], Batch: 89, loss: -6308.97265625\n",
      "Epoch: [31/35], Batch: 29, loss: -6679.9208984375\n",
      "Epoch: [31/35], Batch: 59, loss: -5314.72900390625\n",
      "Epoch: [31/35], Batch: 89, loss: -7612.38525390625\n",
      "Epoch: [32/35], Batch: 29, loss: -5850.380859375\n",
      "Epoch: [32/35], Batch: 59, loss: -3856.689208984375\n",
      "Epoch: [32/35], Batch: 89, loss: -8766.046875\n",
      "Epoch: [33/35], Batch: 29, loss: -7498.80712890625\n",
      "Epoch: [33/35], Batch: 59, loss: -7609.20361328125\n",
      "Epoch: [33/35], Batch: 89, loss: -8353.9697265625\n",
      "Epoch: [34/35], Batch: 29, loss: -6243.849609375\n",
      "Epoch: [34/35], Batch: 59, loss: -6653.16162109375\n",
      "Epoch: [34/35], Batch: 89, loss: -4730.3994140625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "train and test VAE model on airfoils\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "#from dataset import AirfoilDataset\n",
    "#from vae import VAE\n",
    "#from utils import *\n",
    "\n",
    "\n",
    "def main():\n",
    "    # check if cuda available\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # define dataset and dataloader\n",
    "    dataset = AirfoilDataset()\n",
    "    airfoil_x = dataset.get_x()\n",
    "    airfoil_dim = airfoil_x.shape[0]\n",
    "    airfoil_dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # hyperparameters\n",
    "    latent_dim = 16 # please do not change latent dimension\n",
    "    lr = 0.001      # learning rate\n",
    "    num_epochs = 35\n",
    "\n",
    "    # build the model\n",
    "    vae = VAE(airfoil_dim=airfoil_dim, latent_dim=latent_dim).to(device)\n",
    "    print(\"VAE model:\\n\", vae)\n",
    "\n",
    "    # define your loss function here\n",
    "    # loss = ?\n",
    "    def loss_function(recon_x, x, mu, logvar):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, airfoil_dim), reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return BCE + KLD\n",
    "    # define optimizer for discriminator and generator separately\n",
    "    optim = Adam(vae.parameters(), lr=lr)\n",
    "    \n",
    "    # train the VAE model\n",
    "    for epoch in range(num_epochs):\n",
    "        vae.train() #\n",
    "        train_loss = 0 #\n",
    "        for n_batch, (local_batch, __) in enumerate(airfoil_dataloader):\n",
    "            y_real = local_batch.to(device)\n",
    "            optim.zero_grad()\n",
    "            # train VAE\n",
    "            # calculate customized VAE loss\n",
    "            # loss = your_loss_func(...)\n",
    "            recon_batch, mu, logvar = vae(y_real)\n",
    "            loss = loss_function(recon_batch, y_real,mu,logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item() \n",
    "            optim.step()\n",
    "\n",
    "            # print loss while training\n",
    "            if (n_batch + 1) % 30 == 0:\n",
    "                print(\"Epoch: [{}/{}], Batch: {}, loss: {}\".format(\n",
    "                    epoch, num_epochs, n_batch, loss.item()))\n",
    "\n",
    "    # test trained VAE model\n",
    "    num_samples = 100\n",
    "\n",
    "    # reconstuct airfoils\n",
    "    real_airfoils = dataset.get_y()[:num_samples]\n",
    "    recon_airfoils, __, __ = vae(torch.from_numpy(real_airfoils).to(device))\n",
    "    if 'cuda' in device:\n",
    "        recon_airfoils = recon_airfoils.detach().cpu().numpy()\n",
    "    else:\n",
    "        recon_airfoils = recon_airfoils.detach().numpy()\n",
    "    \n",
    "    # randomly synthesize airfoils\n",
    "    noise = torch.randn((num_samples, latent_dim)).to(device)   # create random noise \n",
    "    gen_airfoils = vae.decode(noise)\n",
    "    if 'cuda' in device:\n",
    "        gen_airfoils = gen_airfoils.detach().cpu().numpy()\n",
    "    else:\n",
    "        gen_airfoils = gen_airfoils.detach().numpy()\n",
    "\n",
    "    # plot real/reconstructed/synthesized airfoils\n",
    "    plot_airfoils(airfoil_x, real_airfoils)\n",
    "    plot_airfoils(airfoil_x, recon_airfoils)\n",
    "    plot_airfoils(airfoil_x, gen_airfoils)\n",
    "    \n",
    "    torch.save(vae,'p1_vae_model_V4.pth')\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
